# Information-in-Language
This is a fun little experiment where we are trying to understand the information in language! We attempt to measure the information content and vagueness of true/false statements in language within a given context by modeling them with a minimum complexity neural net.

The sigmoid function classifer used in the neural nets is a fundamental result from the most basic systems studied in classical mechanics, and neural nets can theoretically model any continuous function. As a result, we believe neural networks can be used to define a new fundamental unit of information in the context of statements and language. In addition, by examining the the accuracy of the network with different complexities, we can begin to quantify vagueness in language and perhaps even look for more efficient representations of language!

We also strive to link together multiple statements to understand how much extra complexity is necessary to model a statememnt after verification of a previous statement vs allowing that statement to stand alone or training a single neural net to model both statememnts simultaneously. For example, if `a` and `b` are floats rounded to two decimal places, we can start by modeling the statement `a**2 + b**2 == 1` and find out how much complexity is required to model the statememnt `a == b` given that the previous statement is true. We can compare this complexity to that which is required to model `a == b` without the previous statement and the complexity of modeling the logical combination of both statements, `a**2 + b**2 == 1 and a==b` or `a**2 + b**2 == 1 or a == b` . 

Our initial toy models come from mathematics. We chose these statements since they are precise and we can easily generate training and validation datasets for them. 
