{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "sys.path.insert(0, '..')\n",
    "from net_framework import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Lnum</th>\n",
       "      <th>#snum</th>\n",
       "      <th>#cnum</th>\n",
       "      <th>Term Abbrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>LE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>LF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #Lnum  #snum  #cnum Term Abbrev\n",
       "0      1      1      1          LB\n",
       "1      1      1      2          LB\n",
       "2      1      1      3          LE\n",
       "3      1      1      4          WK\n",
       "4      1      1      5          LF"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\n",
    "term_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\n",
    "term_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#cnum</th>\n",
       "      <th>V</th>\n",
       "      <th>H</th>\n",
       "      <th>C</th>\n",
       "      <th>MunH</th>\n",
       "      <th>MunV</th>\n",
       "      <th>L*</th>\n",
       "      <th>a*</th>\n",
       "      <th>b*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00RP</td>\n",
       "      <td>9.5</td>\n",
       "      <td>96.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00RP</td>\n",
       "      <td>9.0</td>\n",
       "      <td>91.08</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50R</td>\n",
       "      <td>9.0</td>\n",
       "      <td>91.08</td>\n",
       "      <td>5.53</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00R</td>\n",
       "      <td>9.0</td>\n",
       "      <td>91.08</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.50R</td>\n",
       "      <td>9.0</td>\n",
       "      <td>91.08</td>\n",
       "      <td>5.54</td>\n",
       "      <td>4.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>305</td>\n",
       "      <td>I</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>2.50RP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.54</td>\n",
       "      <td>34.44</td>\n",
       "      <td>-14.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>267</td>\n",
       "      <td>I</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>5.00RP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.54</td>\n",
       "      <td>35.44</td>\n",
       "      <td>-10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>243</td>\n",
       "      <td>I</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>7.50RP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.54</td>\n",
       "      <td>35.97</td>\n",
       "      <td>-6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>182</td>\n",
       "      <td>I</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>10.00RP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.54</td>\n",
       "      <td>36.42</td>\n",
       "      <td>-2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>89</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00RP</td>\n",
       "      <td>1.5</td>\n",
       "      <td>15.60</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #cnum  V   H  C     MunH  MunV     L*     a*     b*\n",
       "0      141  A   0  0  10.00RP   9.5  96.00  -0.06   0.06\n",
       "1      274  B   0  0  10.00RP   9.0  91.08  -0.05   0.06\n",
       "2      129  B   1  2    2.50R   9.0  91.08   5.53   2.22\n",
       "3      230  B   2  2    5.00R   9.0  91.08   5.51   3.28\n",
       "4      302  B   3  2    7.50R   9.0  91.08   5.54   4.46\n",
       "..     ... ..  .. ..      ...   ...    ...    ...    ...\n",
       "325    305  I  37  8   2.50RP   2.0  20.54  34.44 -14.69\n",
       "326    267  I  38  8   5.00RP   2.0  20.54  35.44 -10.40\n",
       "327    243  I  39  8   7.50RP   2.0  20.54  35.97  -6.33\n",
       "328    182  I  40  8  10.00RP   2.0  20.54  36.42  -2.08\n",
       "329     89  J   0  0  10.00RP   1.5  15.60  -0.02   0.02\n",
       "\n",
       "[330 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#cnum</th>\n",
       "      <th>Normalized-L</th>\n",
       "      <th>Normalized-a</th>\n",
       "      <th>Normalized-b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025675</td>\n",
       "      <td>-0.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>-0.025504</td>\n",
       "      <td>-0.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070445</td>\n",
       "      <td>-0.106039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>-0.089951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>-0.072041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #cnum  Normalized-L  Normalized-a  Normalized-b\n",
       "0    141      1.000000     -0.025675     -0.138822\n",
       "1    274      0.876301     -0.025504     -0.138822\n",
       "2    129      0.876301      0.070445     -0.106039\n",
       "3    230      0.876301      0.070101     -0.089951\n",
       "4    302      0.876301      0.070617     -0.072041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\n",
    "display(cnum_data)\n",
    "locations = cnum_data[['#cnum']]\n",
    "locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\n",
    "locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
    "locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n",
    "display(locations.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.sort_values('#cnum')\n",
    "chip_num = list(locations['#cnum'])\n",
    "lab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = term_data[term_data.get('#Lnum').eq(1)]\n",
    "unique_symbols = list(l1['Term Abbrev'].unique())\n",
    "l1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\n",
    "l1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         LB    LE    WK    LF     F     G     S   GB    FU\n",
      "#cnum                                                     \n",
      "1      0.36  0.00  0.00  0.04  0.08  0.52  0.00  0.0  0.00\n",
      "2      0.12  0.00  0.04  0.12  0.60  0.04  0.00  0.0  0.08\n",
      "3      0.00  0.96  0.04  0.00  0.00  0.00  0.00  0.0  0.00\n",
      "4      0.28  0.00  0.40  0.00  0.08  0.04  0.20  0.0  0.00\n",
      "5      0.04  0.00  0.00  0.20  0.68  0.08  0.00  0.0  0.00\n",
      "...     ...   ...   ...   ...   ...   ...   ...  ...   ...\n",
      "326    0.08  0.20  0.36  0.00  0.20  0.00  0.12  0.0  0.04\n",
      "327    0.04  0.00  0.00  0.68  0.20  0.04  0.04  0.0  0.00\n",
      "328    0.64  0.00  0.08  0.00  0.00  0.20  0.08  0.0  0.00\n",
      "329    0.08  0.08  0.40  0.00  0.12  0.00  0.28  0.0  0.04\n",
      "330    0.04  0.00  0.00  0.72  0.24  0.00  0.00  0.0  0.00\n",
      "\n",
      "[330 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\n",
    "l1_result.index += 1\n",
    "l1_result.index.name = '#cnum'\n",
    "l1_result.columns = unique_symbols\n",
    "print(l1_result)\n",
    "chip_norm = []\n",
    "#pull the percentage for each cnum\n",
    "for x in chip_num:\n",
    "    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [4], [5], [6], [3, 3], [7], [8], [4, 4], [9], [3, 3, 3], [10], [5, 5], [3, 4, 3], [11], [3, 5, 3], [12], [6, 6], [4, 4, 4], [13], [4, 5, 4], [14], [7, 7], [4, 6, 4], [15], [5, 5, 5], [16], [8, 8], [5, 6, 5], [17], [5, 7, 5], [18], [9, 9], [6, 6, 6], [19], [6, 7, 6], [20], [10, 10], [6, 8, 6], [21], [7, 7, 7], [22], [11, 11], [7, 8, 7], [23], [7, 9, 7], [24], [12, 12], [8, 8, 8]]\n"
     ]
    }
   ],
   "source": [
    "node_num = range(1,25)\n",
    "layer_num = range(1,4)\n",
    "\n",
    "shape_collection = []\n",
    "\n",
    "def trickle(arr, iteration_left, check):\n",
    "    if iteration_left == 0:\n",
    "        global shape_collection\n",
    "        #running the int fxn to make sure we don't have floats\n",
    "        mp = map(int, arr)\n",
    "        x = list(mp)\n",
    "        if check == sum(x):\n",
    "            shape_collection.append(x)\n",
    "    else:\n",
    "        new_arr = [0]+ arr + [0]\n",
    "        #recursively expanding the list symmetrically\n",
    "        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n",
    "            new_arr[0] += 1\n",
    "            new_arr[1] -= 1\n",
    "            new_arr[-1] += 1\n",
    "            new_arr[-2] -= 1\n",
    "        trickle(new_arr, iteration_left - 1, check)\n",
    "\n",
    "for node in node_num:\n",
    "    for layer in layer_num:\n",
    "        if (node//layer < 3 and node >3) or (node<=3 and layer>1):\n",
    "            continue\n",
    "        if layer%2 == 0:\n",
    "            trickle([node/2, node/2], (layer-2)/2, node)\n",
    "        else:\n",
    "            trickle([node], (layer-1)/2, node)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "print(shape_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Originally designed to find every single permutation\n",
    "#Oops misread directions\n",
    "node_num = range(10, 130, 10)\n",
    "layer_num = range(1,6)\n",
    "\n",
    "def check(arr):\n",
    "    for a in arr:\n",
    "        if a < 3:\n",
    "            return False\n",
    "    inverse = arr[::-1]\n",
    "    if arr == inverse:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "shape_collection = []\n",
    "\n",
    "def trickle_down(node, layer):\n",
    "    if layer > 1:\n",
    "        for i in range(0, node[-1]):\n",
    "            new_arr = node[:-1] + [node[-1]-i] + [i]\n",
    "            trickle_down(new_arr,layer-1)\n",
    "    else:\n",
    "        if check(node):\n",
    "            global shape_collection\n",
    "            shape_collection.append([sum(node), len(node),node])\n",
    "\n",
    "for node in node_num:\n",
    "    for layer in layer_num:\n",
    "        trickle_down([node], layer)\n",
    "\n",
    "print(shape_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, [1], 9), (3, [2], 9), (3, [3], 9), (3, [4], 9), (3, [5], 9), (3, [6], 9), (3, [3, 3], 9), (3, [7], 9), (3, [8], 9), (3, [4, 4], 9), (3, [9], 9), (3, [3, 3, 3], 9), (3, [10], 9), (3, [5, 5], 9), (3, [3, 4, 3], 9), (3, [11], 9), (3, [3, 5, 3], 9), (3, [12], 9), (3, [6, 6], 9), (3, [4, 4, 4], 9), (3, [13], 9), (3, [4, 5, 4], 9), (3, [14], 9), (3, [7, 7], 9), (3, [4, 6, 4], 9), (3, [15], 9), (3, [5, 5, 5], 9), (3, [16], 9), (3, [8, 8], 9), (3, [5, 6, 5], 9), (3, [17], 9), (3, [5, 7, 5], 9), (3, [18], 9), (3, [9, 9], 9), (3, [6, 6, 6], 9), (3, [19], 9), (3, [6, 7, 6], 9), (3, [20], 9), (3, [10, 10], 9), (3, [6, 8, 6], 9), (3, [21], 9), (3, [7, 7, 7], 9), (3, [22], 9), (3, [11, 11], 9), (3, [7, 8, 7], 9), (3, [23], 9), (3, [7, 9, 7], 9), (3, [24], 9), (3, [12, 12], 9), (3, [8, 8, 8], 9)]\n"
     ]
    }
   ],
   "source": [
    "#Number of training iterations\n",
    "num_iters = 500\n",
    "\n",
    "#Listing out the shapes of each model\n",
    "colors_num = len(chip_norm[0])\n",
    "input_size = 3\n",
    "\n",
    "network_shapes = []\n",
    "for s in shape_collection:\n",
    "    network_shapes.append((input_size,s,colors_num))\n",
    "\n",
    "#Learning rate of the network\n",
    "rate = 0.001\n",
    "\n",
    "#Generating Training Data\n",
    "input_train, output_train, input_test, output_test = 0, 0, 0, 0\n",
    "def shuffle():\n",
    "    lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.2, random_state = 3, shuffle = True)\n",
    "    #test run on whole dataset\n",
    "    #lab_train, lab_test = lab_norm, lab_norm\n",
    "    #chip_train, chip_test = chip_norm, chip_norm\n",
    "    input_train = torch.FloatTensor(lab_train)\n",
    "    output_train = torch.FloatTensor(chip_train)\n",
    "    input_test= torch.FloatTensor(lab_test)\n",
    "    output_test = torch.FloatTensor(chip_test)\n",
    "    return input_train, output_train, input_test, output_test\n",
    "\n",
    "print(network_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [1], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11606759577989578'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [2], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11495616286993027'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [3], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11466521769762039'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [4], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11306041479110718'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [5], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11418331414461136'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [6], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11187030375003815'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [3, 3], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11185962706804276'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [7], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11094833165407181'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [8], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10869073867797852'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [4, 4], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11093942821025848'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [9], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11003278940916061'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [3, 3, 3], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11003589630126953'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [10], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.104688361287117'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [5, 5], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10821506381034851'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [3, 4, 3], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11278355866670609'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [11], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10139521956443787'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [3, 5, 3], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11126939207315445'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [12], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10118233412504196'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [6, 6], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10906198620796204'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [4, 4, 4], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10773637145757675'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [13], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10759104788303375'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [4, 5, 4], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.11083993315696716'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [14], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10235469043254852'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [7, 7], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10200235247612'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [4, 6, 4], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10640503466129303'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [15], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09810875356197357'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [5, 5, 5], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09943728148937225'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [16], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.0949464961886406'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [8, 8], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09253856539726257'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [5, 6, 5], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10319925844669342'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [17], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09376247227191925'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [5, 7, 5], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10504996031522751'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [18], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09696535766124725'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [9, 9], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09137873351573944'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [6, 6, 6], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.10468699783086777'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [19], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09222957491874695'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [6, 7, 6], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09869206696748734'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [20], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09198348224163055'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [10, 10], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.08961395174264908'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [6, 8, 6], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09109959751367569'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [21], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09145956486463547'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [7, 7, 7], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.08790615200996399'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [22], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.0920882299542427'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [11, 11], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.09391532838344574'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [7, 8, 7], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.08729183673858643'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [23], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.08784531056880951'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [7, 9, 7], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Error: 0.08894345164299011'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [24], 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#27 Error: 0.10326918214559555'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-70047e0bcf93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m#validation_error = NN.l1error(output_test, NN(input_test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Research_Projects\\Information-in-Language\\Perceptron Networks\\net_framework.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Does the update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msaveWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;31m# we will use the PyTorch internal storage functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Array of losses over training period for each network\n",
    "output_file = {}\n",
    "for n in node_num:\n",
    "    output_file[n] = {}\n",
    "    \n",
    "for net_num, shape in enumerate(network_shapes):\n",
    "    #input_train, output_train, input_test, output_test = shuffle()\n",
    "    input_train,output_train=torch.FloatTensor(lab_norm), torch.FloatTensor(chip_norm)\n",
    "    print(\"Training: \",shape)\n",
    "    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n",
    "                        hiddenSize = shape[1] , learning_rate = rate)\n",
    "    error_arr = []\n",
    "    prev_error = 0\n",
    "    strike = 0\n",
    "    \n",
    "    for i in range(num_iters):       \n",
    "        NN.train(input_train, output_train)\n",
    "        #validation_error = NN.l1error(output_test, NN(input_test))\n",
    "        error=NN.l1error(output_train, NN(input_train))\n",
    "        #zero mistake counter at new training\n",
    "        if i == 0:\n",
    "            strike = 0\n",
    "        #adding error to array\n",
    "        error_arr.append(error)\n",
    "        #wait for them to grow up\n",
    "        if i == 0: \n",
    "            dh = display(\"#\" + str(i) + \" Error: \" + str(error), display_id=True)\n",
    "        else:\n",
    "            dh.update(\"#\" + str(i) + \" Error: \" + str(error))\n",
    "        '''\n",
    "        if prev_error < validation_error and i > 100:\n",
    "            if strike > 10:\n",
    "                print(\"Complete at iteration \", i, \"\\nFinal error: \", min(error_arr), \"\\n\")\n",
    "                break\n",
    "            else:\n",
    "                strike += 1\n",
    "        prev_error = error\n",
    "        '''\n",
    "    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n",
    "    #NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num))\n",
    "    output_file[sum(shape[1])][len(shape[1])] = error_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('errors.json', 'w') as f:\n",
    "    json.dump(output_file, f)"
   ]
  }
 ],
 "metadata": {
  "history": [
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "idx": 0,
    "time": "2021-01-20T18:41:05.939Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "idx": 1,
    "time": "2021-01-20T18:41:05.946Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "4fd00db43d74435dba582a93ac732f39",
    "idx": 2,
    "time": "2021-01-20T18:41:05.948Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "idx": 3,
    "time": "2021-01-20T18:41:05.950Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "idx": 4,
    "time": "2021-01-20T18:41:05.953Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "idx": 5,
    "time": "2021-01-20T18:41:05.954Z",
    "type": "execution"
   },
   {
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "time": "2021-01-20T18:41:11.110Z",
    "type": "completion"
   },
   {
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "time": "2021-01-20T18:41:11.504Z",
    "type": "completion"
   },
   {
    "id": "4fd00db43d74435dba582a93ac732f39",
    "time": "2021-01-20T18:41:11.585Z",
    "type": "completion"
   },
   {
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "time": "2021-01-20T18:41:11.587Z",
    "type": "completion"
   },
   {
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "time": "2021-01-20T18:41:11.595Z",
    "type": "completion"
   },
   {
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "time": "2021-01-20T18:41:11.871Z",
    "type": "completion"
   },
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "idx": 0,
    "time": "2021-01-20T18:42:10.430Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "idx": 1,
    "time": "2021-01-20T18:42:10.435Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "4fd00db43d74435dba582a93ac732f39",
    "idx": 2,
    "time": "2021-01-20T18:42:10.436Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "idx": 3,
    "time": "2021-01-20T18:42:10.437Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "idx": 4,
    "time": "2021-01-20T18:42:10.438Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "idx": 5,
    "time": "2021-01-20T18:42:10.439Z",
    "type": "execution"
   },
   {
    "code": "#Originally designed to find every single permutation\n#Oops misread directions\nnode_num = range(10, 130, 10)\nlayer_num = range(1,6)\n\ndef check(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\nshape_collection = []\n\ndef trickle_down(node, layer):\n    if layer > 1:\n        for i in range(0, node[-1]):\n            new_arr = node[:-1] + [node[-1]-i] + [i]\n            trickle_down(new_arr,layer-1)\n    else:\n        if check(node):\n            global shape_collection\n            shape_collection.append(sum(node), len(node),node)\n\nfor node in node_num:\n    for layer in layer_num:\n        trickle_down([node], layer)\n\nprint(shape_collection)",
    "id": "413ad261276748d89dd277b8fabceed0",
    "idx": 7,
    "time": "2021-01-20T18:42:10.446Z",
    "type": "execution"
   },
   {
    "code": "#Number of training iterations\nnum_iters = 500\n\n#Listing out the shapes of each model\ncolors_num = len(chip_norm[0])\ninput_size = 3\n\nnetwork_shapes = []\nfor s in shape_collection:\n    network_shapes.append((input_size,s,colors_num))\n\n#Learning rate of the network\nrate = 0.001\n\n#Generating Training Data\ninput_train, output_train, input_test, output_test = 0, 0, 0, 0\ndef shuffle():\n    lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.2, random_state = 3, shuffle = True)\n    #test run on whole dataset\n    #lab_train, lab_test = lab_norm, lab_norm\n    #chip_train, chip_test = chip_norm, chip_norm\n    \n    global input_train, output_train, input_test, output_test\n    input_train = torch.FloatTensor(lab_train)\n    output_train = torch.FloatTensor(chip_train)\n    input_test= torch.FloatTensor(lab_test)\n    output_test = torch.FloatTensor(chip_test)\n\nprint(network_shapes)",
    "id": "2881ec8a2c8b4d1c89126e11a80dfb8b",
    "idx": 8,
    "time": "2021-01-20T18:42:10.447Z",
    "type": "execution"
   },
   {
    "code": "#Array of losses over training period for each network\noutput_file = {}\nfor n in node_num:\n    output_file[n] = {}\n    \nfor net_num, shape in enumerate(network_shapes):\n    shuffle()\n    print(\"Training: \",shape)\n    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n                        hiddenSize = shape[1] , learning_rate = rate)\n    error_arr = []\n    prev_error = 0\n    strike = 0\n    \n    for i in range(num_iters):       \n        NN.train(input_train, output_train)\n        validation_error = NN.l1error(output_test, NN(input_test))\n        #zero mistake counter at new training\n        if i == 0:\n            strike = 0\n        #adding error to array\n        error_arr.append(validation_error)\n        #wait for them to grow up\n        if prev_error < validation_error and i > 100:\n            if strike > 3:\n                print(\"Complete at iteration \", i, \"\\nFinal error: \", validation_error, \"\\n\")\n                break\n            else:\n                strike += 1\n        prev_error = validation_error\n\n    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num))\n    output_file[sum(shape[1])][len(shape[1])] = error_arr",
    "id": "82de63d5a1c94978ab0eb3b95bcb444d",
    "idx": 9,
    "time": "2021-01-20T18:42:10.448Z",
    "type": "execution"
   },
   {
    "code": "with open('validation_errors.json', 'w') as f:\n    json.dump(output_file, f)",
    "id": "2941038e293a41a39f99076758f6b743",
    "idx": 10,
    "time": "2021-01-20T18:42:10.449Z",
    "type": "execution"
   },
   {
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "time": "2021-01-20T18:42:10.515Z",
    "type": "completion"
   },
   {
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "time": "2021-01-20T18:42:10.777Z",
    "type": "completion"
   },
   {
    "id": "4fd00db43d74435dba582a93ac732f39",
    "time": "2021-01-20T18:42:10.813Z",
    "type": "completion"
   },
   {
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "time": "2021-01-20T18:42:10.815Z",
    "type": "completion"
   },
   {
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "time": "2021-01-20T18:42:10.859Z",
    "type": "completion"
   },
   {
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "time": "2021-01-20T18:42:11.109Z",
    "type": "completion"
   },
   {
    "id": "413ad261276748d89dd277b8fabceed0",
    "time": "2021-01-20T18:42:11.246Z",
    "type": "completion"
   },
   {
    "id": "2881ec8a2c8b4d1c89126e11a80dfb8b",
    "time": "2021-01-20T18:42:11.291Z",
    "type": "completion"
   },
   {
    "id": "82de63d5a1c94978ab0eb3b95bcb444d",
    "time": "2021-01-20T18:42:11.292Z",
    "type": "completion"
   },
   {
    "id": "2941038e293a41a39f99076758f6b743",
    "time": "2021-01-20T18:42:11.293Z",
    "type": "completion"
   },
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "idx": 0,
    "time": "2021-01-20T18:42:23.296Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "idx": 1,
    "time": "2021-01-20T18:42:23.298Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "4fd00db43d74435dba582a93ac732f39",
    "idx": 2,
    "time": "2021-01-20T18:42:23.299Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "idx": 3,
    "time": "2021-01-20T18:42:23.300Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "idx": 4,
    "time": "2021-01-20T18:42:23.300Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "idx": 5,
    "time": "2021-01-20T18:42:23.301Z",
    "type": "execution"
   },
   {
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "time": "2021-01-20T18:42:23.351Z",
    "type": "completion"
   },
   {
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "time": "2021-01-20T18:42:23.680Z",
    "type": "completion"
   },
   {
    "id": "4fd00db43d74435dba582a93ac732f39",
    "time": "2021-01-20T18:42:23.754Z",
    "type": "completion"
   },
   {
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "time": "2021-01-20T18:42:23.760Z",
    "type": "completion"
   },
   {
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "time": "2021-01-20T18:42:23.775Z",
    "type": "completion"
   },
   {
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "time": "2021-01-20T18:42:24.101Z",
    "type": "completion"
   },
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "idx": 0,
    "time": "2021-01-20T18:42:40.686Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "idx": 1,
    "time": "2021-01-20T18:42:40.689Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "4fd00db43d74435dba582a93ac732f39",
    "idx": 2,
    "time": "2021-01-20T18:42:40.692Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "idx": 3,
    "time": "2021-01-20T18:42:40.694Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "idx": 4,
    "time": "2021-01-20T18:42:40.696Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "idx": 5,
    "time": "2021-01-20T18:42:40.697Z",
    "type": "execution"
   },
   {
    "id": "25416a549cd04f4487e7bd5f8618d338",
    "time": "2021-01-20T18:42:40.763Z",
    "type": "completion"
   },
   {
    "id": "85a33b45f61648a08e12c86fe4413df7",
    "time": "2021-01-20T18:42:41.031Z",
    "type": "completion"
   },
   {
    "id": "4fd00db43d74435dba582a93ac732f39",
    "time": "2021-01-20T18:42:41.060Z",
    "type": "completion"
   },
   {
    "id": "1d186efc421a4fff8972cbc8e044bfdb",
    "time": "2021-01-20T18:42:41.062Z",
    "type": "completion"
   },
   {
    "id": "797406f9da5c4e788dd5f6fe416ecec9",
    "time": "2021-01-20T18:42:41.096Z",
    "type": "completion"
   },
   {
    "id": "e7dff5ca819048459a6ae624e6d6ce7b",
    "time": "2021-01-20T18:42:41.368Z",
    "type": "completion"
   },
   {
    "code": "#Originally designed to find every single permutation\n#Oops misread directions\nnode_num = range(10, 130, 10)\nlayer_num = range(1,6)\n\ndef check(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\nshape_collection = []\n\ndef trickle_down(node, layer):\n    if layer > 1:\n        for i in range(0, node[-1]):\n            new_arr = node[:-1] + [node[-1]-i] + [i]\n            trickle_down(new_arr,layer-1)\n    else:\n        if check(node):\n            global shape_collection\n            shape_collection.append([sum(node), len(node),node])\n\nfor node in node_num:\n    for layer in layer_num:\n        trickle_down([node], layer)\n\nprint(shape_collection)",
    "id": "413ad261276748d89dd277b8fabceed0",
    "idx": 7,
    "time": "2021-01-20T18:42:44.847Z",
    "type": "execution"
   },
   {
    "id": "413ad261276748d89dd277b8fabceed0",
    "time": "2021-01-20T18:43:04.794Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        shape_collection.append(arr)\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < newarr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:22:13.009Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:22:13.170Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        shape_collection.append(arr)\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < new_arr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:22:34.197Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:22:34.257Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        shape_collection.append(int(arr))\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < new_arr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:22:46.609Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:22:46.699Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        shape_collection.append(map(int, arr))\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < new_arr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:23:28.317Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:23:28.409Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        shape_collection.append(map(int(), arr))\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < new_arr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:24:13.934Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:24:14.009Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        shape_collection.append(int() for a in arr)\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < new_arr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:24:36.786Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:24:36.857Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        shape_collection.append([int() for a in arr])\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < new_arr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:24:46.105Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:24:46.210Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\ndef isSym(arr):\n    for a in arr:\n        if a < 3:\n            return False\n    inverse = arr[::-1]\n    if arr == inverse:\n        return True\n    else:\n        return False\n\n#mirroring an array\ndef mirror(arr, desired_length):\n    if desired_length/len(arr) == 2:\n        return arr + arr[::-1]\n    else:\n        return arr[:-1] + arr[::-1]\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        mp = map(int, arr)\n        shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        while new_arr[0] < new_arr[1] and new_arr[-1] < new_arr[-2]:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "idx": 6,
    "time": "2021-01-21T06:26:20.137Z",
    "type": "execution"
   },
   {
    "id": "b7af04b8481d454c986fca4090fb1c49",
    "time": "2021-01-21T06:26:20.217Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-1 and new_arr[-1] < new_arr[-2]-1:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "778aa23fe0964fc68f4f15bb72d70497",
    "idx": 6,
    "time": "2021-01-21T06:28:14.496Z",
    "type": "execution"
   },
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "886db2efd9c44203846cf9591e5d8a47",
    "idx": 0,
    "time": "2021-01-21T16:23:24.417Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "80a642188e3c4aafa156162e09d65ca3",
    "idx": 1,
    "time": "2021-01-21T16:23:24.422Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "ac8f69921065472d83f57a6376110a1b",
    "idx": 2,
    "time": "2021-01-21T16:23:24.424Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "56295541b30f497ea0d28bcb5942ff31",
    "idx": 3,
    "time": "2021-01-21T16:23:24.426Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "0e74bb0162df475e83147e0fb05107ad",
    "idx": 4,
    "time": "2021-01-21T16:23:24.427Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "a089d6fe1bc64a7c912cf53edce64f04",
    "idx": 5,
    "time": "2021-01-21T16:23:24.429Z",
    "type": "execution"
   },
   {
    "code": "node_num = range(10, 130, 10)\nlayer_num = range(1,6)\n# checking if the array is symmetrical\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "815d9b5e736f482d8316e2e6a940788a",
    "idx": 6,
    "time": "2021-01-21T16:23:24.432Z",
    "type": "execution"
   },
   {
    "code": "#Number of training iterations\nnum_iters = 500\n\n#Listing out the shapes of each model\ncolors_num = len(chip_norm[0])\ninput_size = 3\n\nnetwork_shapes = []\nfor s in shape_collection:\n    network_shapes.append((input_size,s,colors_num))\n\n#Learning rate of the network\nrate = 0.001\n\n#Generating Training Data\ninput_train, output_train, input_test, output_test = 0, 0, 0, 0\ndef shuffle():\n    lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.2, random_state = 3, shuffle = True)\n    #test run on whole dataset\n    #lab_train, lab_test = lab_norm, lab_norm\n    #chip_train, chip_test = chip_norm, chip_norm\n    \n    global input_train, output_train, input_test, output_test\n    input_train = torch.FloatTensor(lab_train)\n    output_train = torch.FloatTensor(chip_train)\n    input_test= torch.FloatTensor(lab_test)\n    output_test = torch.FloatTensor(chip_test)\n\nprint(network_shapes)",
    "id": "79ed4b747cad49c7a2de4809fcfa1151",
    "idx": 8,
    "time": "2021-01-21T16:23:24.434Z",
    "type": "execution"
   },
   {
    "code": "#Array of losses over training period for each network\noutput_file = {}\nfor n in node_num:\n    output_file[n] = {}\n    \nfor net_num, shape in enumerate(network_shapes):\n    shuffle()\n    print(\"Training: \",shape)\n    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n                        hiddenSize = shape[1] , learning_rate = rate)\n    error_arr = []\n    prev_error = 0\n    strike = 0\n    \n    for i in range(num_iters):       \n        NN.train(input_train, output_train)\n        validation_error = NN.l1error(output_test, NN(input_test))\n        #zero mistake counter at new training\n        if i == 0:\n            strike = 0\n        #adding error to array\n        error_arr.append(validation_error)\n        #wait for them to grow up\n        if prev_error < validation_error and i > 100:\n            if strike > 3:\n                print(\"Complete at iteration \", i, \"\\nFinal error: \", validation_error, \"\\n\")\n                break\n            else:\n                strike += 1\n        prev_error = validation_error\n\n    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num))\n    output_file[sum(shape[1])][len(shape[1])] = error_arr",
    "id": "d4e5d1e9abc2436bab9f7d21808a5d63",
    "idx": 9,
    "time": "2021-01-21T16:23:24.435Z",
    "type": "execution"
   },
   {
    "code": "with open('validation_errors.json', 'w') as f:\n    json.dump(output_file, f)",
    "id": "c554ed2026a9416580e12acdf78759e4",
    "idx": 10,
    "time": "2021-01-21T16:23:24.437Z",
    "type": "execution"
   },
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "59adedb13eb742bd898d6dc87106ff22",
    "idx": 0,
    "time": "2021-01-23T02:59:37.965Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "67bf808b7be74c1db1c728676af35131",
    "idx": 1,
    "time": "2021-01-23T02:59:37.972Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "fbe01656aff44e099be9c52ec3b8ae22",
    "idx": 2,
    "time": "2021-01-23T02:59:37.975Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "9bad1c0bb3e5485f841c664cc610e383",
    "idx": 3,
    "time": "2021-01-23T02:59:37.979Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "3dab680f0eb9475b8505e7de56fbc36f",
    "idx": 4,
    "time": "2021-01-23T02:59:37.981Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "69f27a8e26f743e7b098d022ec67f6c6",
    "idx": 5,
    "time": "2021-01-23T02:59:37.982Z",
    "type": "execution"
   },
   {
    "id": "59adedb13eb742bd898d6dc87106ff22",
    "time": "2021-01-23T02:59:40.527Z",
    "type": "completion"
   },
   {
    "id": "67bf808b7be74c1db1c728676af35131",
    "time": "2021-01-23T02:59:40.846Z",
    "type": "completion"
   },
   {
    "id": "fbe01656aff44e099be9c52ec3b8ae22",
    "time": "2021-01-23T02:59:40.886Z",
    "type": "completion"
   },
   {
    "id": "9bad1c0bb3e5485f841c664cc610e383",
    "time": "2021-01-23T02:59:40.889Z",
    "type": "completion"
   },
   {
    "id": "3dab680f0eb9475b8505e7de56fbc36f",
    "time": "2021-01-23T02:59:40.906Z",
    "type": "completion"
   },
   {
    "id": "69f27a8e26f743e7b098d022ec67f6c6",
    "time": "2021-01-23T02:59:41.155Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,2)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T02:59:43.329Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T02:59:43.412Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,3)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:00:40.394Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:00:40.495Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:01:02.834Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:01:02.882Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3 or not node//layer == node/layer:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:01:47.636Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:01:47.692Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        if sum(arr) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, sum[arr])\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:04:01.112Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:04:01.327Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        if sum(arr) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, sum(arr)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:04:11.971Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:04:12.020Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        if sum(arr) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, sum(arr))\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:04:22.464Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:04:22.532Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        if sum(arr) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, sum(arr))\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:04:31.429Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:04:31.504Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        if sum(arr) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:04:51.482Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:04:51.532Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        if sum(list(mp)) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:05:30.694Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:05:30.752Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        print(list(mp))\n        if sum(list(mp)) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:05:42.130Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:05:42.222Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        #print(list(mp))\n        if sum(list(mp)) == check:\n            shape_collection.append(list(mp))\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:06:12.373Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:06:12.457Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        x = list(mp)\n        shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:06:37.874Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:06:37.971Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        x = list(mp)\n        print(sum(x))\n        shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:06:52.677Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:06:52.756Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int(), arr)\n        x = list(mp)\n        print(sum(x))\n        shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:07:22.733Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:07:22.819Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        #mp = map(int, arr)\n       # x = list(mp)\n        print(arr)\n        shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:07:42.114Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:07:42.187Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        x = list(mp)\n        print(sum(x))\n        shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:07:59.327Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:07:59.384Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        x = list(mp)\n        print(sum(x), check)\n        shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:09:11.574Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:09:11.677Z",
    "type": "completion"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        x = list(mp)\n        if check == sum(x):\n            shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:09:26.604Z",
    "type": "execution"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:09:26.680Z",
    "type": "completion"
   },
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "59adedb13eb742bd898d6dc87106ff22",
    "idx": 0,
    "time": "2021-01-23T03:09:43.443Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "67bf808b7be74c1db1c728676af35131",
    "idx": 1,
    "time": "2021-01-23T03:09:43.444Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "fbe01656aff44e099be9c52ec3b8ae22",
    "idx": 2,
    "time": "2021-01-23T03:09:43.445Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "9bad1c0bb3e5485f841c664cc610e383",
    "idx": 3,
    "time": "2021-01-23T03:09:43.446Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "3dab680f0eb9475b8505e7de56fbc36f",
    "idx": 4,
    "time": "2021-01-23T03:09:43.447Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "69f27a8e26f743e7b098d022ec67f6c6",
    "idx": 5,
    "time": "2021-01-23T03:09:43.448Z",
    "type": "execution"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        x = list(mp)\n        if check == sum(x):\n            shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:09:43.451Z",
    "type": "execution"
   },
   {
    "code": "#Number of training iterations\nnum_iters = 500\n\n#Listing out the shapes of each model\ncolors_num = len(chip_norm[0])\ninput_size = 3\n\nnetwork_shapes = []\nfor s in shape_collection:\n    network_shapes.append((input_size,s,colors_num))\n\n#Learning rate of the network\nrate = 0.001\n\n#Generating Training Data\ninput_train, output_train, input_test, output_test = 0, 0, 0, 0\ndef shuffle():\n    lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.2, random_state = 3, shuffle = True)\n    #test run on whole dataset\n    #lab_train, lab_test = lab_norm, lab_norm\n    #chip_train, chip_test = chip_norm, chip_norm\n    \n    global input_train, output_train, input_test, output_test\n    input_train = torch.FloatTensor(lab_train)\n    output_train = torch.FloatTensor(chip_train)\n    input_test= torch.FloatTensor(lab_test)\n    output_test = torch.FloatTensor(chip_test)\n\nprint(network_shapes)",
    "id": "ee151fd81e224b6dbc1f58e993564c02",
    "idx": 8,
    "time": "2021-01-23T03:09:43.452Z",
    "type": "execution"
   },
   {
    "code": "#Array of losses over training period for each network\noutput_file = {}\nfor n in node_num:\n    output_file[n] = {}\n    \nfor net_num, shape in enumerate(network_shapes):\n    shuffle()\n    print(\"Training: \",shape)\n    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n                        hiddenSize = shape[1] , learning_rate = rate)\n    error_arr = []\n    prev_error = 0\n    strike = 0\n    \n    for i in range(num_iters):       \n        NN.train(input_train, output_train)\n        validation_error = NN.l1error(output_test, NN(input_test))\n        #zero mistake counter at new training\n        if i == 0:\n            strike = 0\n        #adding error to array\n        error_arr.append(validation_error)\n        #wait for them to grow up\n        if prev_error < validation_error and i > 100:\n            if strike > 3:\n                print(\"Complete at iteration \", i, \"\\nFinal error: \", validation_error, \"\\n\")\n                break\n            else:\n                strike += 1\n        prev_error = validation_error\n\n    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num))\n    output_file[sum(shape[1])][len(shape[1])] = error_arr",
    "id": "b8b7900f1ad64169be6e65e68e8a7f1a",
    "idx": 9,
    "time": "2021-01-23T03:09:43.453Z",
    "type": "execution"
   },
   {
    "code": "with open('validation_errors.json', 'w') as f:\n    json.dump(output_file, f)",
    "id": "7333cb2902254eab803d94d93fbf488f",
    "idx": 10,
    "time": "2021-01-23T03:09:43.454Z",
    "type": "execution"
   },
   {
    "id": "59adedb13eb742bd898d6dc87106ff22",
    "time": "2021-01-23T03:09:43.496Z",
    "type": "completion"
   },
   {
    "id": "67bf808b7be74c1db1c728676af35131",
    "time": "2021-01-23T03:09:43.778Z",
    "type": "completion"
   },
   {
    "id": "fbe01656aff44e099be9c52ec3b8ae22",
    "time": "2021-01-23T03:09:43.810Z",
    "type": "completion"
   },
   {
    "id": "9bad1c0bb3e5485f841c664cc610e383",
    "time": "2021-01-23T03:09:43.811Z",
    "type": "completion"
   },
   {
    "id": "3dab680f0eb9475b8505e7de56fbc36f",
    "time": "2021-01-23T03:09:43.842Z",
    "type": "completion"
   },
   {
    "id": "69f27a8e26f743e7b098d022ec67f6c6",
    "time": "2021-01-23T03:09:44.086Z",
    "type": "completion"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:09:44.104Z",
    "type": "completion"
   },
   {
    "id": "ee151fd81e224b6dbc1f58e993564c02",
    "time": "2021-01-23T03:09:44.126Z",
    "type": "completion"
   },
   {
    "id": "b8b7900f1ad64169be6e65e68e8a7f1a",
    "time": "2021-01-23T03:09:51.984Z",
    "type": "completion"
   },
   {
    "id": "7333cb2902254eab803d94d93fbf488f",
    "time": "2021-01-23T03:09:51.986Z",
    "type": "completion"
   },
   {
    "code": "import sys\nimport math\nimport numpy as np\nsys.path.insert(0, '..')\nfrom net_framework import *\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport json",
    "id": "59adedb13eb742bd898d6dc87106ff22",
    "idx": 0,
    "time": "2021-01-23T03:09:59.689Z",
    "type": "execution"
   },
   {
    "code": "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\nterm_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\nterm_data.head()",
    "id": "67bf808b7be74c1db1c728676af35131",
    "idx": 1,
    "time": "2021-01-23T03:09:59.690Z",
    "type": "execution"
   },
   {
    "code": "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\nlocations = cnum_data[['#cnum']]\nlocations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\nlocations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\nlocations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\ndisplay(locations.head(5))",
    "id": "fbe01656aff44e099be9c52ec3b8ae22",
    "idx": 2,
    "time": "2021-01-23T03:09:59.692Z",
    "type": "execution"
   },
   {
    "code": "locations = locations.sort_values('#cnum')\nchip_num = list(locations['#cnum'])\nlab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]",
    "id": "9bad1c0bb3e5485f841c664cc610e383",
    "idx": 3,
    "time": "2021-01-23T03:09:59.693Z",
    "type": "execution"
   },
   {
    "code": "l1 = term_data[term_data.get('#Lnum').eq(1)]\nunique_symbols = list(l1['Term Abbrev'].unique())\nl1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\nl1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]",
    "id": "3dab680f0eb9475b8505e7de56fbc36f",
    "idx": 4,
    "time": "2021-01-23T03:09:59.693Z",
    "type": "execution"
   },
   {
    "code": "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\nl1_result.index += 1\nl1_result.index.name = '#cnum'\nl1_result.columns = unique_symbols\nprint(l1_result)\nchip_norm = []\n#pull the percentage for each cnum\nfor x in chip_num:\n    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])",
    "id": "69f27a8e26f743e7b098d022ec67f6c6",
    "idx": 5,
    "time": "2021-01-23T03:09:59.694Z",
    "type": "execution"
   },
   {
    "code": "node_num = range(1,25)\nlayer_num = range(1,4)\n\n\nshape_collection = []\n\ndef trickle(arr, iteration_left, check):\n    if iteration_left == 0:\n        global shape_collection\n        #running the int fxn to make sure we don't have floats\n        mp = map(int, arr)\n        x = list(mp)\n        if check == sum(x):\n            shape_collection.append(x)\n    else:\n        new_arr = [0]+ arr + [0]\n        #recursively expanding the list symmetrically\n        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n            new_arr[0] += 1\n            new_arr[1] -= 1\n            new_arr[-1] += 1\n            new_arr[-2] -= 1\n        trickle(new_arr, iteration_left - 1, check)\n\nfor node in node_num:\n    for layer in layer_num:\n        if node//layer < 3:\n            continue\n        if layer%2 == 0:\n            trickle([node/2, node/2], (layer-2)/2, node)\n        else:\n            trickle([node], (layer-1)/2, node)\n        \n        \n        \n        \n\nprint(shape_collection)",
    "id": "8fc63966a8424c7db16629d9659432f8",
    "idx": 6,
    "time": "2021-01-23T03:09:59.696Z",
    "type": "execution"
   },
   {
    "code": "#Number of training iterations\nnum_iters = 500\n\n#Listing out the shapes of each model\ncolors_num = len(chip_norm[0])\ninput_size = 3\n\nnetwork_shapes = []\nfor s in shape_collection:\n    network_shapes.append((input_size,s,colors_num))\n\n#Learning rate of the network\nrate = 0.001\n\n#Generating Training Data\ninput_train, output_train, input_test, output_test = 0, 0, 0, 0\ndef shuffle():\n    lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.2, random_state = 3, shuffle = True)\n    #test run on whole dataset\n    #lab_train, lab_test = lab_norm, lab_norm\n    #chip_train, chip_test = chip_norm, chip_norm\n    \n    global input_train, output_train, input_test, output_test\n    input_train = torch.FloatTensor(lab_train)\n    output_train = torch.FloatTensor(chip_train)\n    input_test= torch.FloatTensor(lab_test)\n    output_test = torch.FloatTensor(chip_test)\n\nprint(network_shapes)",
    "id": "ee151fd81e224b6dbc1f58e993564c02",
    "idx": 8,
    "time": "2021-01-23T03:09:59.697Z",
    "type": "execution"
   },
   {
    "code": "#Array of losses over training period for each network\noutput_file = {}\nfor n in node_num:\n    output_file[n] = {}\n    \nfor net_num, shape in enumerate(network_shapes):\n    shuffle()\n    print(\"Training: \",shape)\n    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n                        hiddenSize = shape[1] , learning_rate = rate)\n    error_arr = []\n    prev_error = 0\n    strike = 0\n    \n    for i in range(num_iters):       \n        NN.train(input_train, output_train)\n        validation_error = NN.l1error(output_test, NN(input_test))\n        #zero mistake counter at new training\n        if i == 0:\n            strike = 0\n        #adding error to array\n        error_arr.append(validation_error)\n        #wait for them to grow up\n        if prev_error < validation_error and i > 100:\n            if strike > 3:\n                print(\"Complete at iteration \", i, \"\\nFinal error: \", validation_error, \"\\n\")\n                break\n            else:\n                strike += 1\n        prev_error = validation_error\n\n    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num))\n    output_file[sum(shape[1])][len(shape[1])] = error_arr",
    "id": "b8b7900f1ad64169be6e65e68e8a7f1a",
    "idx": 9,
    "time": "2021-01-23T03:09:59.699Z",
    "type": "execution"
   },
   {
    "code": "with open('validation_errors.json', 'w') as f:\n    json.dump(output_file, f)",
    "id": "7333cb2902254eab803d94d93fbf488f",
    "idx": 10,
    "time": "2021-01-23T03:09:59.700Z",
    "type": "execution"
   },
   {
    "id": "59adedb13eb742bd898d6dc87106ff22",
    "time": "2021-01-23T03:10:01.352Z",
    "type": "completion"
   },
   {
    "id": "67bf808b7be74c1db1c728676af35131",
    "time": "2021-01-23T03:10:01.616Z",
    "type": "completion"
   },
   {
    "id": "fbe01656aff44e099be9c52ec3b8ae22",
    "time": "2021-01-23T03:10:01.691Z",
    "type": "completion"
   },
   {
    "id": "9bad1c0bb3e5485f841c664cc610e383",
    "time": "2021-01-23T03:10:01.693Z",
    "type": "completion"
   },
   {
    "id": "3dab680f0eb9475b8505e7de56fbc36f",
    "time": "2021-01-23T03:10:01.694Z",
    "type": "completion"
   },
   {
    "id": "69f27a8e26f743e7b098d022ec67f6c6",
    "time": "2021-01-23T03:10:01.983Z",
    "type": "completion"
   },
   {
    "id": "8fc63966a8424c7db16629d9659432f8",
    "time": "2021-01-23T03:10:02.017Z",
    "type": "completion"
   },
   {
    "id": "ee151fd81e224b6dbc1f58e993564c02",
    "time": "2021-01-23T03:10:02.019Z",
    "type": "completion"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "277px",
    "left": "800px",
    "right": "20px",
    "top": "69px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
