{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "sys.path.insert(0, '..')\n",
    "from net_framework import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Lnum</th>\n",
       "      <th>#snum</th>\n",
       "      <th>#cnum</th>\n",
       "      <th>Term Abbrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>LE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>LF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #Lnum  #snum  #cnum Term Abbrev\n",
       "0      1      1      1          LB\n",
       "1      1      1      2          LB\n",
       "2      1      1      3          LE\n",
       "3      1      1      4          WK\n",
       "4      1      1      5          LF"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\n",
    "term_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\n",
    "term_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-102-f811cbef4bec>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\n",
      "<ipython-input-102-f811cbef4bec>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
      "<ipython-input-102-f811cbef4bec>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#cnum</th>\n",
       "      <th>Normalized-L</th>\n",
       "      <th>Normalized-a</th>\n",
       "      <th>Normalized-b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025675</td>\n",
       "      <td>-0.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>-0.025504</td>\n",
       "      <td>-0.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070445</td>\n",
       "      <td>-0.106039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>-0.089951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>-0.072041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #cnum  Normalized-L  Normalized-a  Normalized-b\n",
       "0    141      1.000000     -0.025675     -0.138822\n",
       "1    274      0.876301     -0.025504     -0.138822\n",
       "2    129      0.876301      0.070445     -0.106039\n",
       "3    230      0.876301      0.070101     -0.089951\n",
       "4    302      0.876301      0.070617     -0.072041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\n",
    "locations = cnum_data[['#cnum']]\n",
    "locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\n",
    "locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
    "locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n",
    "display(locations.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.sort_values('#cnum')\n",
    "chip_num = list(locations['#cnum'])\n",
    "lab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = term_data[term_data.get('#Lnum').eq(1)]\n",
    "unique_symbols = list(l1['Term Abbrev'].unique())\n",
    "l1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\n",
    "l1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         LB    LE    WK    LF     F     G     S   GB    FU\n",
      "#cnum                                                     \n",
      "1      0.36  0.00  0.00  0.04  0.08  0.52  0.00  0.0  0.00\n",
      "2      0.12  0.00  0.04  0.12  0.60  0.04  0.00  0.0  0.08\n",
      "3      0.00  0.96  0.04  0.00  0.00  0.00  0.00  0.0  0.00\n",
      "4      0.28  0.00  0.40  0.00  0.08  0.04  0.20  0.0  0.00\n",
      "5      0.04  0.00  0.00  0.20  0.68  0.08  0.00  0.0  0.00\n",
      "...     ...   ...   ...   ...   ...   ...   ...  ...   ...\n",
      "326    0.08  0.20  0.36  0.00  0.20  0.00  0.12  0.0  0.04\n",
      "327    0.04  0.00  0.00  0.68  0.20  0.04  0.04  0.0  0.00\n",
      "328    0.64  0.00  0.08  0.00  0.00  0.20  0.08  0.0  0.00\n",
      "329    0.08  0.08  0.40  0.00  0.12  0.00  0.28  0.0  0.04\n",
      "330    0.04  0.00  0.00  0.72  0.24  0.00  0.00  0.0  0.00\n",
      "\n",
      "[330 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\n",
    "l1_result.index += 1\n",
    "l1_result.index.name = '#cnum'\n",
    "l1_result.columns = unique_symbols\n",
    "print(l1_result)\n",
    "chip_norm = []\n",
    "#pull the percentage for each cnum\n",
    "for x in chip_num:\n",
    "    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10], [5, 5], [4, 2, 4], [20], [10, 10], [8, 4, 8], [7, 3, 3, 7], [6, 3, 2, 3, 6], [30], [15, 15], [2, 26, 2], [8, 7, 7, 8], [6, 3, 12, 3, 6], [40], [20, 20], [4, 32, 4], [6, 14, 14, 6], [10, 6, 8, 6, 10], [50], [25, 25], [6, 38, 6], [13, 12, 12, 13], [14, 8, 6, 8, 14], [60], [30, 30], [23, 14, 23], [9, 21, 21, 9], [24, 4, 4, 4, 24], [70], [35, 35], [32, 6, 32], [24, 11, 11, 24], [3, 21, 22, 21, 3], [80], [40, 40], [10, 60, 10], [31, 9, 9, 31], [32, 4, 8, 4, 32], [90], [45, 45], [15, 60, 15], [9, 36, 36, 9], [8, 8, 58, 8, 8], [100], [50, 50], [44, 12, 44], [43, 7, 7, 43], [41, 8, 2, 8, 41], [110], [55, 55], [25, 60, 25], [3, 52, 52, 3], [2, 16, 74, 16, 2], [120], [60, 60], [43, 34, 43], [36, 24, 24, 36], [23, 19, 36, 19, 23]]\n"
     ]
    }
   ],
   "source": [
    "node_num = range(10, 130, 10)\n",
    "layer_num = range(1,6)\n",
    "def mirror(arr, desired_length):\n",
    "    if desired_length/len(arr) == 2:\n",
    "        return arr + arr[::-1]\n",
    "    else:\n",
    "        return arr[:-1] + arr[::-1]\n",
    "\n",
    "shape_collection = []\n",
    "for node in node_num:\n",
    "    for layer in layer_num:\n",
    "        shape = []\n",
    "        # it gets stuck on this particular one for some reason\n",
    "        if layer == 1:\n",
    "            shape = [node]\n",
    "            shape_collection.append(shape)\n",
    "        elif node//layer < 3:\n",
    "            continue\n",
    "        elif layer%2 == 0:\n",
    "            # you are not leaving until you give me the right number\n",
    "            while sum(shape) != node/2:\n",
    "                shape = []\n",
    "                # let the code randomly assign things that add up to what we want\n",
    "                for l in range (0,int(layer/2)) :\n",
    "                    shape.append(int(random.uniform(3,node+1)))\n",
    "            \n",
    "            shape = mirror(shape, layer)\n",
    "            shape_collection.append(shape)\n",
    "        else:\n",
    "            while sum(shape) != node:\n",
    "                shape = []\n",
    "                # similar logic, but we let it mirror itself first\n",
    "                for l in range (0, math.ceil(layer/2)) :\n",
    "                    shape.append(random.randint(2,node))\n",
    "                shape = mirror(shape, layer)    \n",
    "            shape_collection.append(shape)\n",
    "\n",
    "print(shape_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally designed to find every single permutation\n",
    "Oops misread directions\n",
    "\n",
    "\n",
    "def check(arr):\n",
    "    for a in arr:\n",
    "        if a < 3:\n",
    "            return False\n",
    "    inverse = arr[::-1]\n",
    "    if arr == inverse:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "shape_collection = []\n",
    "\n",
    "def trickle_down(node, layer):\n",
    "    if layer > 1:\n",
    "        for i in range(0, node[-1]):\n",
    "            new_arr = node[:-1] + [node[-1]-i] + [i]\n",
    "            trickle_down(new_arr,layer-1)\n",
    "    else:\n",
    "        if check(node):\n",
    "            global shape_collection\n",
    "            shape_collection.append(node)\n",
    "\n",
    "for node in node_num:\n",
    "    for layer in layer_num:\n",
    "        trickle_down([node], layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, [10], 9), (3, [5, 5], 9), (3, [4, 2, 4], 9), (3, [20], 9), (3, [10, 10], 9), (3, [8, 4, 8], 9), (3, [7, 3, 3, 7], 9), (3, [6, 3, 2, 3, 6], 9), (3, [30], 9), (3, [15, 15], 9), (3, [2, 26, 2], 9), (3, [8, 7, 7, 8], 9), (3, [6, 3, 12, 3, 6], 9), (3, [40], 9), (3, [20, 20], 9), (3, [4, 32, 4], 9), (3, [6, 14, 14, 6], 9), (3, [10, 6, 8, 6, 10], 9), (3, [50], 9), (3, [25, 25], 9), (3, [6, 38, 6], 9), (3, [13, 12, 12, 13], 9), (3, [14, 8, 6, 8, 14], 9), (3, [60], 9), (3, [30, 30], 9), (3, [23, 14, 23], 9), (3, [9, 21, 21, 9], 9), (3, [24, 4, 4, 4, 24], 9), (3, [70], 9), (3, [35, 35], 9), (3, [32, 6, 32], 9), (3, [24, 11, 11, 24], 9), (3, [3, 21, 22, 21, 3], 9), (3, [80], 9), (3, [40, 40], 9), (3, [10, 60, 10], 9), (3, [31, 9, 9, 31], 9), (3, [32, 4, 8, 4, 32], 9), (3, [90], 9), (3, [45, 45], 9), (3, [15, 60, 15], 9), (3, [9, 36, 36, 9], 9), (3, [8, 8, 58, 8, 8], 9), (3, [100], 9), (3, [50, 50], 9), (3, [44, 12, 44], 9), (3, [43, 7, 7, 43], 9), (3, [41, 8, 2, 8, 41], 9), (3, [110], 9), (3, [55, 55], 9), (3, [25, 60, 25], 9), (3, [3, 52, 52, 3], 9), (3, [2, 16, 74, 16, 2], 9), (3, [120], 9), (3, [60, 60], 9), (3, [43, 34, 43], 9), (3, [36, 24, 24, 36], 9), (3, [23, 19, 36, 19, 23], 9)]\n"
     ]
    }
   ],
   "source": [
    "#Number of training iterations\n",
    "num_iters = 500\n",
    "\n",
    "#Listing out the shapes of each model\n",
    "colors_num = len(chip_norm[0])\n",
    "input_size = 3\n",
    "\n",
    "network_shapes = []\n",
    "for s in shape_collection:\n",
    "    network_shapes.append((input_size,s,colors_num))\n",
    "\n",
    "#Learning rate of the network\n",
    "rate = 0.001\n",
    "\n",
    "#Generating Training Data\n",
    "input_train, output_train, input_test, output_test = 0, 0, 0, 0\n",
    "def shuffle():\n",
    "    lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.2, random_state = 3, shuffle = True)\n",
    "    #test run on whole dataset\n",
    "    #lab_train, lab_test = lab_norm, lab_norm\n",
    "    #chip_train, chip_test = chip_norm, chip_norm\n",
    "    \n",
    "    global input_train, output_train, input_test, output_test\n",
    "    input_train = torch.FloatTensor(lab_train)\n",
    "    output_train = torch.FloatTensor(chip_train)\n",
    "    input_test= torch.FloatTensor(lab_test)\n",
    "    output_test = torch.FloatTensor(chip_test)\n",
    "\n",
    "print(network_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [10], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.12613445520401 \n",
      "\n",
      "Training:  (3, [5, 5], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.12572301924228668 \n",
      "\n",
      "Training:  (3, [4, 2, 4], 9)\n",
      "Complete at iteration  144 \n",
      "Final error:  0.12210437655448914 \n",
      "\n",
      "Training:  (3, [20], 9)\n",
      "Complete at iteration  109 \n",
      "Final error:  0.11713770031929016 \n",
      "\n",
      "Training:  (3, [10, 10], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.13037103414535522 \n",
      "\n",
      "Training:  (3, [8, 4, 8], 9)\n",
      "Complete at iteration  111 \n",
      "Final error:  0.13116085529327393 \n",
      "\n",
      "Training:  (3, [7, 3, 3, 7], 9)\n",
      "Complete at iteration  112 \n",
      "Final error:  0.12910564243793488 \n",
      "\n",
      "Training:  (3, [6, 3, 2, 3, 6], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.12291418015956879 \n",
      "\n",
      "Training:  (3, [30], 9)\n",
      "Complete at iteration  116 \n",
      "Final error:  0.13103528320789337 \n",
      "\n",
      "Training:  (3, [15, 15], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.14439505338668823 \n",
      "\n",
      "Training:  (3, [2, 26, 2], 9)\n",
      "Complete at iteration  110 \n",
      "Final error:  0.11369609087705612 \n",
      "\n",
      "Training:  (3, [8, 7, 7, 8], 9)\n",
      "Complete at iteration  108 \n",
      "Final error:  0.12691740691661835 \n",
      "\n",
      "Training:  (3, [6, 3, 12, 3, 6], 9)\n",
      "Complete at iteration  152 \n",
      "Final error:  0.11758759617805481 \n",
      "\n",
      "Training:  (3, [40], 9)\n",
      "Complete at iteration  116 \n",
      "Final error:  0.1255532056093216 \n",
      "\n",
      "Training:  (3, [50], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16069649159908295 \n",
      "\n",
      "Training:  (3, [25, 25], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.1670127958059311 \n",
      "\n",
      "Training:  (3, [6, 38, 6], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.15603409707546234 \n",
      "\n",
      "Training:  (3, [13, 12, 12, 13], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.15841002762317657 \n",
      "\n",
      "Training:  (3, [14, 8, 6, 8, 14], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.12556958198547363 \n",
      "\n",
      "Training:  (3, [60], 9)\n",
      "Complete at iteration  107 \n",
      "Final error:  0.17003141343593597 \n",
      "\n",
      "Training:  (3, [30, 30], 9)\n",
      "Complete at iteration  107 \n",
      "Final error:  0.16259576380252838 \n",
      "\n",
      "Training:  (3, [23, 14, 23], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.1734175831079483 \n",
      "\n",
      "Training:  (3, [9, 21, 21, 9], 9)\n",
      "Complete at iteration  121 \n",
      "Final error:  0.14759306609630585 \n",
      "\n",
      "Training:  (3, [24, 4, 4, 4, 24], 9)\n",
      "Complete at iteration  113 \n",
      "Final error:  0.12083802372217178 \n",
      "\n",
      "Training:  (3, [70], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16363589465618134 \n",
      "\n",
      "Training:  (3, [35, 35], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16995185613632202 \n",
      "\n",
      "Training:  (3, [32, 6, 32], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.15457306802272797 \n",
      "\n",
      "Training:  (3, [24, 11, 11, 24], 9)\n",
      "Complete at iteration  106 \n",
      "Final error:  0.1691538393497467 \n",
      "\n",
      "Training:  (3, [3, 21, 22, 21, 3], 9)\n",
      "Complete at iteration  108 \n",
      "Final error:  0.11993517726659775 \n",
      "\n",
      "Training:  (3, [80], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16192777454853058 \n",
      "\n",
      "Training:  (3, [40, 40], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.18588466942310333 \n",
      "\n",
      "Training:  (3, [10, 60, 10], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.14995375275611877 \n",
      "\n",
      "Training:  (3, [31, 9, 9, 31], 9)\n",
      "Complete at iteration  129 \n",
      "Final error:  0.1623312085866928 \n",
      "\n",
      "Training:  (3, [32, 4, 8, 4, 32], 9)\n",
      "Complete at iteration  106 \n",
      "Final error:  0.12039033323526382 \n",
      "\n",
      "Training:  (3, [90], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.18143439292907715 \n",
      "\n",
      "Training:  (3, [45, 45], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.17215023934841156 \n",
      "\n",
      "Training:  (3, [15, 60, 15], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16338029503822327 \n",
      "\n",
      "Training:  (3, [9, 36, 36, 9], 9)\n",
      "Complete at iteration  106 \n",
      "Final error:  0.1567867547273636 \n",
      "\n",
      "Training:  (3, [8, 8, 58, 8, 8], 9)\n",
      "Complete at iteration  135 \n",
      "Final error:  0.12060949951410294 \n",
      "\n",
      "Training:  (3, [100], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.191200852394104 \n",
      "\n",
      "Training:  (3, [50, 50], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.15966270864009857 \n",
      "\n",
      "Training:  (3, [44, 12, 44], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16554930806159973 \n",
      "\n",
      "Training:  (3, [43, 7, 7, 43], 9)\n",
      "Complete at iteration  108 \n",
      "Final error:  0.1378772258758545 \n",
      "\n",
      "Training:  (3, [41, 8, 2, 8, 41], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.14040659368038177 \n",
      "\n",
      "Training:  (3, [110], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.18391701579093933 \n",
      "\n",
      "Training:  (3, [55, 55], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16490881145000458 \n",
      "\n",
      "Training:  (3, [25, 60, 25], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16650187969207764 \n",
      "\n",
      "Training:  (3, [3, 52, 52, 3], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.1422567069530487 \n",
      "\n",
      "Training:  (3, [2, 16, 74, 16, 2], 9)\n",
      "Complete at iteration  111 \n",
      "Final error:  0.11622440069913864 \n",
      "\n",
      "Training:  (3, [120], 9)\n",
      "Complete at iteration  107 \n",
      "Final error:  0.1869453489780426 \n",
      "\n",
      "Training:  (3, [60, 60], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.17022980749607086 \n",
      "\n",
      "Training:  (3, [43, 34, 43], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.1663713902235031 \n",
      "\n",
      "Training:  (3, [36, 24, 24, 36], 9)\n",
      "Complete at iteration  105 \n",
      "Final error:  0.16184769570827484 \n",
      "\n",
      "Training:  (3, [23, 19, 36, 19, 23], 9)\n"
     ]
    }
   ],
   "source": [
    "#Array of losses over training period for each network\n",
    "output_file = {}\n",
    "for n in node_num:\n",
    "    output_file[n] = {}\n",
    "    \n",
    "for net_num, shape in enumerate(network_shapes):\n",
    "    shuffle()\n",
    "    print(\"Training: \",shape)\n",
    "    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n",
    "                        hiddenSize = shape[1] , learning_rate = rate)\n",
    "    error_arr = []\n",
    "    prev_error = 0\n",
    "    strike = 0\n",
    "    \n",
    "    for i in range(num_iters):       \n",
    "        NN.train(input_train, output_train)\n",
    "        validation_error = NN.l1error(output_test, NN(input_test))\n",
    "        #zero mistake counter at new training\n",
    "        if i == 0:\n",
    "            strike = 0\n",
    "        #adding error to array\n",
    "        error_arr.append(validation_error)\n",
    "        #wait for them to grow up\n",
    "        if prev_error < validation_error and i > 100:\n",
    "            if strike > 3:\n",
    "                print(\"Complete at iteration \", i, \"\\nFinal error: \", validation_error, \"\\n\")\n",
    "                break\n",
    "            else:\n",
    "                strike += 1\n",
    "        prev_error = validation_error\n",
    "\n",
    "    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n",
    "    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num))\n",
    "    output_file[sum(shape[1])][len(shape[1])] = error_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_errors.json', 'w') as f:\n",
    "    json.dump(output_file, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "277px",
    "left": "800px",
    "right": "20px",
    "top": "69px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
