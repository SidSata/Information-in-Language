{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from net_framework import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Lnum</th>\n",
       "      <th>#snum</th>\n",
       "      <th>#cnum</th>\n",
       "      <th>Term Abbrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>LE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>LF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #Lnum  #snum  #cnum Term Abbrev\n",
       "0      1      1      1          LB\n",
       "1      1      1      2          LB\n",
       "2      1      1      3          LE\n",
       "3      1      1      4          WK\n",
       "4      1      1      5          LF"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\n",
    "term_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\n",
    "term_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-f811cbef4bec>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\n",
      "<ipython-input-23-f811cbef4bec>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
      "<ipython-input-23-f811cbef4bec>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#cnum</th>\n",
       "      <th>Normalized-L</th>\n",
       "      <th>Normalized-a</th>\n",
       "      <th>Normalized-b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025675</td>\n",
       "      <td>-0.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>-0.025504</td>\n",
       "      <td>-0.138822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070445</td>\n",
       "      <td>-0.106039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>-0.089951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>0.876301</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>-0.072041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #cnum  Normalized-L  Normalized-a  Normalized-b\n",
       "0    141      1.000000     -0.025675     -0.138822\n",
       "1    274      0.876301     -0.025504     -0.138822\n",
       "2    129      0.876301      0.070445     -0.106039\n",
       "3    230      0.876301      0.070101     -0.089951\n",
       "4    302      0.876301      0.070617     -0.072041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\n",
    "locations = cnum_data[['#cnum']]\n",
    "locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\n",
    "locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
    "locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n",
    "display(locations.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141, 274, 129, 230, 302, 324, 27, 290, 92, 66, 83, 22, 242, 106, 177, 260, 206, 52, 199, 95, 293, 219, 108, 330, 221, 284, 327, 244, 294, 272, 172, 158, 120, 286, 262, 107, 241, 319, 224, 314, 252, 44, 16, 217, 201, 84, 56, 237, 6, 159, 174, 297, 96, 12, 128, 214, 124, 306, 149, 251, 67, 229, 5, 196, 100, 2, 31, 175, 74, 116, 264, 189, 303, 142, 70, 139, 59, 15, 78, 285, 190, 160, 292, 300, 63, 151, 35, 278, 318, 212, 187, 110, 326, 146, 258, 193, 91, 143, 33, 315, 268, 29, 161, 145, 253, 82, 289, 186, 49, 200, 104, 138, 322, 254, 102, 213, 167, 99, 152, 215, 86, 118, 239, 126, 263, 256, 176, 17, 121, 125, 261, 270, 48, 181, 42, 275, 218, 236, 81, 7, 282, 45, 180, 310, 119, 147, 246, 136, 55, 40, 211, 19, 153, 1, 37, 233, 62, 308, 197, 273, 32, 68, 28, 21, 173, 46, 321, 298, 288, 3, 76, 30, 185, 208, 287, 58, 225, 320, 304, 280, 195, 20, 202, 85, 299, 223, 301, 316, 238, 77, 307, 188, 169, 34, 164, 291, 220, 247, 192, 23, 231, 269, 203, 207, 65, 112, 154, 98, 148, 245, 132, 266, 9, 329, 295, 183, 232, 103, 69, 165, 171, 54, 39, 122, 234, 72, 156, 281, 191, 163, 25, 123, 93, 311, 80, 64, 235, 109, 205, 222, 184, 105, 88, 135, 276, 38, 162, 79, 115, 61, 41, 259, 240, 283, 157, 51, 155, 24, 309, 130, 216, 111, 137, 328, 265, 133, 168, 323, 249, 209, 114, 57, 226, 277, 257, 140, 178, 26, 279, 97, 296, 73, 131, 325, 317, 101, 53, 8, 312, 71, 194, 179, 210, 134, 117, 204, 94, 255, 113, 18, 198, 87, 227, 248, 75, 47, 13, 271, 36, 127, 11, 90, 170, 60, 14, 166, 228, 43, 10, 313, 144, 250, 150, 50, 4, 305, 267, 243, 182, 89]\n"
     ]
    }
   ],
   "source": [
    "chip_num = list(locations['#cnum'])\n",
    "lab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]\n",
    "print(chip_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = term_data[term_data.get('#Lnum').eq(1)]\n",
    "unique_symbols = list(l1['Term Abbrev'].unique())\n",
    "l1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\n",
    "l1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         LB    LE    WK    LF     F     G     S   GB    FU\n",
      "#cnum                                                     \n",
      "1      0.36  0.00  0.00  0.04  0.08  0.52  0.00  0.0  0.00\n",
      "2      0.12  0.00  0.04  0.12  0.60  0.04  0.00  0.0  0.08\n",
      "3      0.00  0.96  0.04  0.00  0.00  0.00  0.00  0.0  0.00\n",
      "4      0.28  0.00  0.40  0.00  0.08  0.04  0.20  0.0  0.00\n",
      "5      0.04  0.00  0.00  0.20  0.68  0.08  0.00  0.0  0.00\n",
      "...     ...   ...   ...   ...   ...   ...   ...  ...   ...\n",
      "326    0.08  0.20  0.36  0.00  0.20  0.00  0.12  0.0  0.04\n",
      "327    0.04  0.00  0.00  0.68  0.20  0.04  0.04  0.0  0.00\n",
      "328    0.64  0.00  0.08  0.00  0.00  0.20  0.08  0.0  0.00\n",
      "329    0.08  0.08  0.40  0.00  0.12  0.00  0.28  0.0  0.04\n",
      "330    0.04  0.00  0.00  0.72  0.24  0.00  0.00  0.0  0.00\n",
      "\n",
      "[330 rows x 9 columns]\n",
      "[[0.44, 0.0, 0.0, 0.04, 0.0, 0.52, 0.0, 0.0, 0.0], [0.04, 0.16, 0.24, 0.0, 0.28, 0.08, 0.2, 0.0, 0.0], [0.0, 0.0, 0.2, 0.08, 0.48, 0.04, 0.12, 0.0, 0.08], [0.08, 0.0, 0.04, 0.16, 0.64, 0.0, 0.08, 0.0, 0.0], [0.48, 0.0, 0.04, 0.0, 0.04, 0.4, 0.04, 0.0, 0.0], [0.6, 0.0, 0.04, 0.0, 0.04, 0.24, 0.08, 0.0, 0.0], [0.32, 0.0, 0.0, 0.0, 0.04, 0.6, 0.04, 0.0, 0.0], [0.32, 0.0, 0.04, 0.04, 0.24, 0.24, 0.08, 0.0, 0.04], [0.0, 0.0, 0.28, 0.0, 0.56, 0.0, 0.08, 0.0, 0.08], [0.0, 0.96, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0], [0.12, 0.0, 0.08, 0.12, 0.24, 0.36, 0.04, 0.0, 0.04], [0.0, 0.84, 0.08, 0.04, 0.04, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.04, 0.72, 0.24, 0.0, 0.0, 0.0, 0.0], [0.0, 0.4, 0.28, 0.0, 0.12, 0.0, 0.2, 0.0, 0.0], [0.0, 0.96, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0], [0.04, 0.72, 0.12, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0], [0.12, 0.0, 0.2, 0.0, 0.04, 0.44, 0.16, 0.0, 0.04], [0.36, 0.04, 0.2, 0.0, 0.28, 0.0, 0.12, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.96, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.24, 0.36, 0.04, 0.28, 0.0, 0.08, 0.0, 0.0], [0.24, 0.0, 0.24, 0.0, 0.36, 0.0, 0.16, 0.0, 0.0], [0.0, 0.0, 0.0, 0.56, 0.32, 0.0, 0.08, 0.0, 0.04], [0.08, 0.08, 0.4, 0.0, 0.12, 0.0, 0.28, 0.0, 0.04], [0.28, 0.0, 0.0, 0.0, 0.0, 0.68, 0.04, 0.0, 0.0], [0.24, 0.12, 0.24, 0.0, 0.12, 0.0, 0.24, 0.0, 0.04], [0.08, 0.2, 0.36, 0.0, 0.2, 0.0, 0.12, 0.0, 0.04], [0.24, 0.4, 0.12, 0.0, 0.04, 0.04, 0.16, 0.0, 0.0], [0.0, 0.0, 0.0, 0.44, 0.48, 0.0, 0.04, 0.0, 0.04], [0.8, 0.0, 0.0, 0.0, 0.04, 0.12, 0.04, 0.0, 0.0], [0.32, 0.0, 0.16, 0.0, 0.16, 0.08, 0.2, 0.0, 0.08], [0.44, 0.04, 0.2, 0.04, 0.08, 0.0, 0.2, 0.0, 0.0], [0.28, 0.0, 0.0, 0.04, 0.12, 0.48, 0.04, 0.0, 0.04], [0.0, 0.2, 0.24, 0.04, 0.36, 0.0, 0.12, 0.0, 0.04], [0.0, 0.4, 0.32, 0.0, 0.12, 0.0, 0.12, 0.0, 0.04], [0.0, 0.16, 0.08, 0.16, 0.56, 0.0, 0.0, 0.0, 0.04], [0.32, 0.12, 0.24, 0.0, 0.12, 0.0, 0.2, 0.0, 0.0], [0.0, 0.52, 0.36, 0.0, 0.12, 0.0, 0.0, 0.0, 0.0], [0.44, 0.0, 0.08, 0.0, 0.12, 0.32, 0.04, 0.0, 0.0], [0.36, 0.0, 0.04, 0.0, 0.0, 0.52, 0.08, 0.0, 0.0], [0.08, 0.0, 0.08, 0.2, 0.56, 0.04, 0.04, 0.0, 0.0], [0.6, 0.0, 0.0, 0.0, 0.04, 0.32, 0.04, 0.0, 0.0], [0.0, 0.08, 0.12, 0.12, 0.64, 0.04, 0.0, 0.0, 0.0], [0.84, 0.0, 0.04, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0], [0.24, 0.0, 0.0, 0.08, 0.12, 0.4, 0.16, 0.0, 0.0], [0.0, 0.04, 0.12, 0.32, 0.44, 0.0, 0.08, 0.0, 0.0], [0.24, 0.0, 0.0, 0.04, 0.16, 0.36, 0.16, 0.0, 0.04], [0.0, 0.04, 0.28, 0.0, 0.48, 0.0, 0.12, 0.04, 0.04], [0.04, 0.0, 0.0, 0.2, 0.68, 0.08, 0.0, 0.0, 0.0], [0.04, 0.0, 0.0, 0.84, 0.12, 0.0, 0.0, 0.0, 0.0], [0.0, 0.96, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0], [0.2, 0.0, 0.12, 0.0, 0.08, 0.48, 0.12, 0.0, 0.0], [0.0, 0.0, 0.0, 0.56, 0.36, 0.0, 0.04, 0.0, 0.04], [0.64, 0.0, 0.04, 0.0, 0.12, 0.12, 0.08, 0.0, 0.0], [0.88, 0.0, 0.0, 0.0, 0.0, 0.08, 0.04, 0.0, 0.0], [0.0, 0.0, 0.08, 0.12, 0.36, 0.24, 0.16, 0.0, 0.04], [0.56, 0.0, 0.0, 0.0, 0.08, 0.28, 0.08, 0.0, 0.0], [0.24, 0.16, 0.2, 0.0, 0.08, 0.08, 0.2, 0.04, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2, 0.0, 0.2, 0.0, 0.08, 0.28, 0.24, 0.0, 0.0], [0.0, 0.0, 0.04, 0.48, 0.4, 0.0, 0.04, 0.0, 0.04], [0.48, 0.0, 0.0, 0.0, 0.0, 0.44, 0.04, 0.04, 0.0], [0.28, 0.0, 0.4, 0.0, 0.08, 0.04, 0.2, 0.0, 0.0], [0.44, 0.0, 0.08, 0.0, 0.2, 0.24, 0.0, 0.0, 0.04], [0.04, 0.0, 0.12, 0.12, 0.64, 0.04, 0.0, 0.0, 0.04], [0.36, 0.0, 0.0, 0.04, 0.08, 0.52, 0.0, 0.0, 0.0], [0.04, 0.44, 0.4, 0.0, 0.08, 0.0, 0.04, 0.0, 0.0], [0.0, 0.28, 0.44, 0.0, 0.24, 0.0, 0.04, 0.0, 0.0], [0.12, 0.08, 0.16, 0.0, 0.36, 0.12, 0.16, 0.0, 0.0], [0.0, 0.84, 0.08, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04], [0.32, 0.0, 0.08, 0.12, 0.32, 0.04, 0.12, 0.0, 0.0], [0.44, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.68, 0.28, 0.0, 0.04, 0.0, 0.0], [0.0, 0.0, 0.04, 0.88, 0.08, 0.0, 0.0, 0.0, 0.0], [0.48, 0.0, 0.2, 0.0, 0.12, 0.0, 0.16, 0.0, 0.04], [0.08, 0.0, 0.04, 0.2, 0.28, 0.36, 0.04, 0.0, 0.0], [0.08, 0.0, 0.4, 0.0, 0.12, 0.04, 0.24, 0.04, 0.08], [0.8, 0.0, 0.04, 0.0, 0.0, 0.08, 0.08, 0.0, 0.0], [0.48, 0.0, 0.0, 0.0, 0.04, 0.4, 0.08, 0.0, 0.0], [0.0, 0.0, 0.0, 0.76, 0.24, 0.0, 0.0, 0.0, 0.0], [0.12, 0.0, 0.0, 0.32, 0.32, 0.2, 0.04, 0.0, 0.0], [0.0, 0.28, 0.36, 0.04, 0.28, 0.0, 0.04, 0.0, 0.0], [0.36, 0.0, 0.0, 0.0, 0.0, 0.64, 0.0, 0.0, 0.0], [0.48, 0.0, 0.04, 0.0, 0.04, 0.36, 0.08, 0.0, 0.0], [0.16, 0.0, 0.08, 0.0, 0.24, 0.28, 0.2, 0.0, 0.04], [0.36, 0.04, 0.24, 0.0, 0.04, 0.2, 0.12, 0.0, 0.0], [0.48, 0.0, 0.04, 0.0, 0.0, 0.48, 0.0, 0.0, 0.0], [0.56, 0.0, 0.0, 0.0, 0.04, 0.36, 0.04, 0.0, 0.0], [0.0, 0.76, 0.12, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0], [0.36, 0.0, 0.0, 0.0, 0.12, 0.48, 0.0, 0.0, 0.04], [0.12, 0.0, 0.0, 0.08, 0.36, 0.36, 0.04, 0.0, 0.04], [0.32, 0.0, 0.0, 0.0, 0.04, 0.6, 0.0, 0.04, 0.0], [0.12, 0.32, 0.2, 0.0, 0.04, 0.12, 0.2, 0.0, 0.0], [0.16, 0.0, 0.16, 0.0, 0.36, 0.08, 0.2, 0.0, 0.04], [0.52, 0.0, 0.0, 0.0, 0.0, 0.36, 0.08, 0.04, 0.0], [0.12, 0.0, 0.12, 0.0, 0.32, 0.2, 0.2, 0.0, 0.04], [0.88, 0.0, 0.0, 0.0, 0.0, 0.08, 0.04, 0.0, 0.0], [0.04, 0.0, 0.0, 0.52, 0.36, 0.0, 0.04, 0.0, 0.04], [0.0, 0.28, 0.2, 0.04, 0.24, 0.04, 0.2, 0.0, 0.0], [0.0, 0.0, 0.0, 0.64, 0.28, 0.0, 0.04, 0.0, 0.04], [0.2, 0.24, 0.28, 0.0, 0.08, 0.04, 0.16, 0.0, 0.0], [0.0, 0.96, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.12, 0.36, 0.0, 0.4, 0.0, 0.08, 0.0, 0.04], [0.56, 0.0, 0.04, 0.0, 0.04, 0.28, 0.08, 0.0, 0.0], [0.0, 0.0, 0.08, 0.52, 0.4, 0.0, 0.0, 0.0, 0.0], [0.12, 0.0, 0.2, 0.0, 0.44, 0.0, 0.16, 0.04, 0.04], [0.04, 0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04, 0.32, 0.36, 0.0, 0.16, 0.0, 0.08, 0.0, 0.04], [0.04, 0.16, 0.36, 0.04, 0.24, 0.0, 0.16, 0.0, 0.0], [0.0, 0.0, 0.0, 0.64, 0.28, 0.0, 0.08, 0.0, 0.0], [0.44, 0.0, 0.12, 0.0, 0.24, 0.0, 0.2, 0.0, 0.0], [0.56, 0.0, 0.0, 0.0, 0.12, 0.16, 0.16, 0.0, 0.0], [0.04, 0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32, 0.0, 0.04, 0.0, 0.32, 0.28, 0.04, 0.0, 0.0], [0.0, 0.6, 0.16, 0.0, 0.08, 0.0, 0.16, 0.0, 0.0], [0.0, 0.76, 0.16, 0.0, 0.04, 0.0, 0.04, 0.0, 0.0], [0.72, 0.0, 0.04, 0.0, 0.0, 0.24, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.24, 0.2, 0.08, 0.28, 0.0, 0.2, 0.0, 0.0], [0.08, 0.04, 0.36, 0.0, 0.36, 0.0, 0.16, 0.0, 0.0], [0.6, 0.0, 0.0, 0.0, 0.12, 0.24, 0.04, 0.0, 0.0], [0.68, 0.0, 0.08, 0.0, 0.04, 0.0, 0.2, 0.0, 0.0], [0.56, 0.0, 0.0, 0.0, 0.04, 0.36, 0.04, 0.0, 0.0], [0.0, 0.96, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.72, 0.2, 0.0, 0.04, 0.0, 0.04], [0.96, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.04, 0.28, 0.36, 0.16, 0.12, 0.0, 0.04], [0.04, 0.0, 0.0, 0.8, 0.04, 0.0, 0.08, 0.0, 0.04], [0.0, 0.0, 0.0, 0.68, 0.28, 0.0, 0.04, 0.0, 0.0], [0.0, 0.04, 0.28, 0.0, 0.52, 0.0, 0.16, 0.0, 0.0], [0.0, 0.0, 0.12, 0.32, 0.52, 0.0, 0.04, 0.0, 0.0], [0.04, 0.52, 0.32, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0], [0.8, 0.0, 0.04, 0.04, 0.0, 0.08, 0.04, 0.0, 0.0], [0.36, 0.0, 0.08, 0.0, 0.24, 0.28, 0.0, 0.0, 0.04], [0.04, 0.88, 0.0, 0.0, 0.04, 0.0, 0.04, 0.0, 0.0], [0.0, 0.0, 0.0, 0.96, 0.04, 0.0, 0.0, 0.0, 0.0], [0.0, 0.16, 0.36, 0.0, 0.36, 0.04, 0.04, 0.0, 0.04], [0.44, 0.0, 0.0, 0.0, 0.04, 0.52, 0.0, 0.0, 0.0], [0.48, 0.0, 0.0, 0.0, 0.04, 0.44, 0.04, 0.0, 0.0], [0.0, 0.16, 0.48, 0.08, 0.2, 0.0, 0.08, 0.0, 0.0], [0.48, 0.0, 0.0, 0.0, 0.04, 0.44, 0.04, 0.0, 0.0], [0.04, 0.0, 0.08, 0.44, 0.44, 0.0, 0.0, 0.0, 0.0], [0.12, 0.2, 0.2, 0.0, 0.2, 0.0, 0.28, 0.0, 0.0], [0.92, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04, 0.0, 0.0], [0.0, 0.36, 0.36, 0.0, 0.24, 0.0, 0.04, 0.0, 0.0], [0.0, 0.32, 0.4, 0.04, 0.12, 0.0, 0.08, 0.0, 0.04], [0.04, 0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04, 0.6, 0.2, 0.0, 0.08, 0.0, 0.08, 0.0, 0.0], [0.56, 0.0, 0.16, 0.0, 0.08, 0.04, 0.16, 0.0, 0.0], [0.6, 0.04, 0.12, 0.0, 0.08, 0.08, 0.08, 0.0, 0.0], [0.28, 0.08, 0.28, 0.0, 0.16, 0.0, 0.16, 0.0, 0.04], [0.88, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.0], [0.0, 0.12, 0.28, 0.04, 0.44, 0.0, 0.08, 0.0, 0.04], [0.04, 0.0, 0.0, 0.72, 0.24, 0.0, 0.0, 0.0, 0.0], [0.72, 0.04, 0.0, 0.0, 0.08, 0.08, 0.08, 0.0, 0.0], [0.36, 0.0, 0.28, 0.0, 0.12, 0.0, 0.2, 0.0, 0.04], [0.0, 0.96, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4, 0.0, 0.0, 0.0, 0.08, 0.48, 0.04, 0.0, 0.0], [0.08, 0.0, 0.0, 0.28, 0.52, 0.08, 0.04, 0.0, 0.0], [0.0, 0.0, 0.0, 0.84, 0.16, 0.0, 0.0, 0.0, 0.0], [0.12, 0.04, 0.04, 0.24, 0.36, 0.12, 0.08, 0.0, 0.0], [0.12, 0.0, 0.12, 0.08, 0.4, 0.12, 0.12, 0.0, 0.04], [0.04, 0.0, 0.12, 0.36, 0.44, 0.0, 0.04, 0.0, 0.0], [0.36, 0.0, 0.08, 0.04, 0.32, 0.04, 0.16, 0.0, 0.0], [0.0, 0.0, 0.0, 0.88, 0.12, 0.0, 0.0, 0.0, 0.0], [0.32, 0.0, 0.12, 0.08, 0.12, 0.2, 0.12, 0.0, 0.04], [0.24, 0.0, 0.28, 0.0, 0.08, 0.0, 0.36, 0.04, 0.0], [0.0, 0.36, 0.36, 0.0, 0.24, 0.0, 0.04, 0.0, 0.0], [0.08, 0.08, 0.44, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0], [0.12, 0.0, 0.04, 0.12, 0.6, 0.04, 0.0, 0.0, 0.08], [0.88, 0.0, 0.0, 0.0, 0.0, 0.04, 0.08, 0.0, 0.0], [0.32, 0.04, 0.04, 0.04, 0.36, 0.04, 0.12, 0.0, 0.04], [0.16, 0.0, 0.12, 0.0, 0.16, 0.32, 0.24, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.92, 0.08, 0.0, 0.0, 0.0, 0.0], [0.68, 0.0, 0.0, 0.0, 0.04, 0.28, 0.0, 0.0, 0.0], [0.0, 0.0, 0.08, 0.48, 0.4, 0.0, 0.04, 0.0, 0.0], [0.0, 0.0, 0.0, 0.72, 0.24, 0.0, 0.0, 0.0, 0.04], [0.08, 0.0, 0.04, 0.24, 0.36, 0.16, 0.08, 0.0, 0.04], [0.48, 0.0, 0.0, 0.0, 0.0, 0.52, 0.0, 0.0, 0.0], [0.24, 0.28, 0.12, 0.0, 0.08, 0.12, 0.12, 0.0, 0.04], [0.16, 0.0, 0.08, 0.08, 0.24, 0.44, 0.0, 0.0, 0.0], [0.0, 0.4, 0.36, 0.0, 0.12, 0.0, 0.08, 0.0, 0.04], [0.0, 0.36, 0.28, 0.0, 0.28, 0.0, 0.08, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12, 0.08, 0.12, 0.0, 0.12, 0.44, 0.08, 0.0, 0.04], [0.0, 0.0, 0.0, 0.4, 0.44, 0.0, 0.12, 0.0, 0.04], [0.24, 0.0, 0.12, 0.0, 0.32, 0.12, 0.12, 0.0, 0.08], [0.0, 0.24, 0.44, 0.04, 0.2, 0.0, 0.08, 0.0, 0.0], [0.0, 0.72, 0.24, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0], [0.16, 0.0, 0.12, 0.12, 0.32, 0.08, 0.16, 0.0, 0.04], [0.0, 0.56, 0.36, 0.0, 0.04, 0.0, 0.04, 0.0, 0.0], [0.64, 0.0, 0.04, 0.0, 0.04, 0.16, 0.12, 0.0, 0.0], [0.16, 0.04, 0.16, 0.0, 0.4, 0.12, 0.08, 0.0, 0.04], [0.52, 0.0, 0.04, 0.0, 0.04, 0.36, 0.0, 0.0, 0.04], [0.04, 0.0, 0.12, 0.48, 0.28, 0.0, 0.04, 0.0, 0.04], [0.0, 0.0, 0.0, 0.72, 0.28, 0.0, 0.0, 0.0, 0.0], [0.44, 0.0, 0.04, 0.0, 0.16, 0.24, 0.08, 0.04, 0.0], [0.64, 0.0, 0.0, 0.0, 0.04, 0.28, 0.04, 0.0, 0.0], [0.0, 0.08, 0.16, 0.16, 0.48, 0.0, 0.12, 0.0, 0.0], [0.0, 0.04, 0.24, 0.36, 0.28, 0.0, 0.04, 0.0, 0.04], [0.32, 0.0, 0.08, 0.08, 0.28, 0.16, 0.04, 0.0, 0.04], [0.6, 0.0, 0.04, 0.0, 0.12, 0.24, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.56, 0.4, 0.0, 0.04, 0.0, 0.0], [0.48, 0.0, 0.0, 0.0, 0.04, 0.48, 0.0, 0.0, 0.0], [0.76, 0.0, 0.0, 0.0, 0.04, 0.08, 0.12, 0.0, 0.0], [0.4, 0.0, 0.0, 0.04, 0.04, 0.52, 0.0, 0.0, 0.0], [0.28, 0.0, 0.0, 0.0, 0.08, 0.44, 0.16, 0.0, 0.04], [0.36, 0.0, 0.04, 0.0, 0.12, 0.36, 0.08, 0.0, 0.04], [0.04, 0.0, 0.0, 0.72, 0.2, 0.0, 0.04, 0.0, 0.0], [0.08, 0.08, 0.28, 0.0, 0.12, 0.16, 0.24, 0.04, 0.0], [0.72, 0.0, 0.04, 0.0, 0.04, 0.16, 0.0, 0.04, 0.0], [0.0, 0.72, 0.08, 0.0, 0.12, 0.0, 0.08, 0.0, 0.0], [0.64, 0.0, 0.08, 0.0, 0.0, 0.2, 0.08, 0.0, 0.0], [0.0, 0.0, 0.0, 0.72, 0.2, 0.0, 0.04, 0.0, 0.04], [0.24, 0.28, 0.2, 0.0, 0.12, 0.04, 0.12, 0.0, 0.0], [0.04, 0.28, 0.44, 0.0, 0.04, 0.04, 0.16, 0.0, 0.0], [0.04, 0.0, 0.08, 0.28, 0.36, 0.12, 0.08, 0.0, 0.04], [0.0, 0.56, 0.24, 0.0, 0.12, 0.0, 0.08, 0.0, 0.0], [0.32, 0.0, 0.0, 0.0, 0.0, 0.68, 0.0, 0.0, 0.0], [0.8, 0.0, 0.0, 0.0, 0.0, 0.12, 0.08, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04, 0.84, 0.08, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0], [0.0, 0.96, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08, 0.0, 0.08, 0.08, 0.24, 0.4, 0.12, 0.0, 0.0], [0.16, 0.28, 0.28, 0.0, 0.24, 0.0, 0.04, 0.0, 0.0], [0.84, 0.0, 0.0, 0.0, 0.08, 0.0, 0.08, 0.0, 0.0], [0.28, 0.0, 0.08, 0.0, 0.28, 0.12, 0.2, 0.0, 0.04], [0.0, 0.2, 0.4, 0.0, 0.24, 0.0, 0.16, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8, 0.0, 0.08, 0.0, 0.04, 0.0, 0.08, 0.0, 0.0], [0.6, 0.0, 0.0, 0.0, 0.12, 0.24, 0.04, 0.0, 0.0], [0.0, 0.0, 0.08, 0.44, 0.36, 0.0, 0.08, 0.0, 0.04], [0.28, 0.0, 0.08, 0.0, 0.24, 0.32, 0.04, 0.0, 0.04], [0.88, 0.0, 0.04, 0.0, 0.04, 0.04, 0.0, 0.0, 0.0], [0.0, 0.44, 0.16, 0.04, 0.28, 0.0, 0.08, 0.0, 0.0], [0.52, 0.0, 0.04, 0.0, 0.12, 0.28, 0.04, 0.0, 0.0], [0.0, 0.0, 0.0, 0.4, 0.44, 0.04, 0.08, 0.0, 0.04], [0.96, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04, 0.0, 0.0, 0.64, 0.28, 0.0, 0.04, 0.0, 0.0], [0.36, 0.0, 0.16, 0.0, 0.36, 0.0, 0.12, 0.0, 0.0], [0.16, 0.0, 0.0, 0.12, 0.32, 0.36, 0.04, 0.0, 0.0], [0.92, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0], [0.44, 0.0, 0.08, 0.0, 0.2, 0.0, 0.28, 0.0, 0.0], [0.04, 0.0, 0.44, 0.0, 0.24, 0.0, 0.28, 0.0, 0.0], [0.32, 0.0, 0.12, 0.0, 0.12, 0.36, 0.08, 0.0, 0.0], [0.32, 0.0, 0.08, 0.0, 0.2, 0.24, 0.12, 0.0, 0.04], [0.0, 0.08, 0.12, 0.16, 0.6, 0.0, 0.0, 0.0, 0.04], [0.6, 0.0, 0.0, 0.0, 0.04, 0.32, 0.04, 0.0, 0.0], [0.96, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0], [0.28, 0.0, 0.04, 0.12, 0.16, 0.28, 0.12, 0.0, 0.0], [0.0, 0.08, 0.4, 0.0, 0.32, 0.0, 0.16, 0.0, 0.04], [0.0, 0.44, 0.28, 0.0, 0.16, 0.0, 0.12, 0.0, 0.0], [0.2, 0.0, 0.2, 0.0, 0.24, 0.2, 0.12, 0.0, 0.04], [0.4, 0.0, 0.08, 0.0, 0.04, 0.4, 0.04, 0.04, 0.0], [0.32, 0.04, 0.32, 0.0, 0.04, 0.08, 0.2, 0.0, 0.0], [0.76, 0.0, 0.0, 0.04, 0.04, 0.04, 0.12, 0.0, 0.0], [0.12, 0.04, 0.32, 0.04, 0.2, 0.12, 0.12, 0.0, 0.04], [0.12, 0.0, 0.2, 0.04, 0.36, 0.12, 0.16, 0.0, 0.0], [0.0, 0.0, 0.0, 0.56, 0.4, 0.0, 0.0, 0.0, 0.04], [0.0, 0.28, 0.28, 0.0, 0.32, 0.0, 0.08, 0.0, 0.04], [0.0, 0.56, 0.32, 0.0, 0.04, 0.0, 0.08, 0.0, 0.0], [0.4, 0.0, 0.0, 0.04, 0.08, 0.48, 0.0, 0.0, 0.0], [0.04, 0.0, 0.0, 0.68, 0.2, 0.04, 0.04, 0.0, 0.0], [0.12, 0.0, 0.0, 0.28, 0.36, 0.16, 0.08, 0.0, 0.0], [0.0, 0.88, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04], [0.0, 0.0, 0.12, 0.12, 0.6, 0.0, 0.12, 0.0, 0.04], [0.2, 0.0, 0.0, 0.16, 0.16, 0.48, 0.0, 0.0, 0.0], [0.92, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0], [0.12, 0.2, 0.4, 0.0, 0.08, 0.0, 0.16, 0.0, 0.04], [0.96, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.24, 0.2, 0.08, 0.44, 0.0, 0.04, 0.0, 0.0], [0.16, 0.0, 0.28, 0.04, 0.24, 0.04, 0.24, 0.0, 0.0], [0.0, 0.92, 0.04, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0], [0.0, 0.96, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.04, 0.56, 0.32, 0.0, 0.04, 0.0, 0.04], [0.0, 0.0, 0.04, 0.16, 0.68, 0.0, 0.08, 0.0, 0.04], [0.44, 0.0, 0.08, 0.0, 0.08, 0.36, 0.04, 0.0, 0.0], [0.0, 0.56, 0.32, 0.0, 0.04, 0.0, 0.08, 0.0, 0.0], [0.0, 0.4, 0.4, 0.0, 0.12, 0.0, 0.08, 0.0, 0.0], [0.24, 0.0, 0.44, 0.0, 0.0, 0.0, 0.28, 0.04, 0.0], [0.48, 0.0, 0.0, 0.04, 0.08, 0.28, 0.12, 0.0, 0.0], [0.76, 0.0, 0.08, 0.0, 0.08, 0.04, 0.04, 0.0, 0.0], [0.0, 0.0, 0.0, 0.64, 0.36, 0.0, 0.0, 0.0, 0.0], [0.36, 0.0, 0.08, 0.0, 0.04, 0.44, 0.04, 0.04, 0.0], [0.04, 0.0, 0.08, 0.28, 0.4, 0.12, 0.08, 0.0, 0.0], [0.04, 0.0, 0.04, 0.6, 0.24, 0.04, 0.04, 0.0, 0.0], [0.24, 0.0, 0.04, 0.04, 0.32, 0.2, 0.16, 0.0, 0.0], [0.36, 0.0, 0.0, 0.0, 0.04, 0.6, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.48, 0.32, 0.0, 0.16, 0.0, 0.04], [0.04, 0.0, 0.28, 0.0, 0.44, 0.0, 0.16, 0.04, 0.04], [0.44, 0.0, 0.0, 0.0, 0.04, 0.52, 0.0, 0.0, 0.0], [0.68, 0.0, 0.0, 0.0, 0.0, 0.28, 0.04, 0.0, 0.0], [0.68, 0.0, 0.0, 0.04, 0.0, 0.28, 0.0, 0.0, 0.0], [0.08, 0.0, 0.0, 0.48, 0.2, 0.12, 0.08, 0.0, 0.04], [0.04, 0.68, 0.2, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0], [0.4, 0.0, 0.0, 0.04, 0.0, 0.56, 0.0, 0.0, 0.0], [0.12, 0.0, 0.04, 0.04, 0.36, 0.4, 0.04, 0.0, 0.0], [0.04, 0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04, 0.12, 0.32, 0.0, 0.32, 0.0, 0.2, 0.0, 0.0], [0.0, 0.52, 0.2, 0.0, 0.2, 0.0, 0.08, 0.0, 0.0], [0.64, 0.0, 0.0, 0.0, 0.0, 0.32, 0.04, 0.0, 0.0], [0.28, 0.0, 0.2, 0.0, 0.04, 0.24, 0.24, 0.0, 0.0], [0.08, 0.0, 0.0, 0.4, 0.32, 0.12, 0.04, 0.0, 0.04], [0.4, 0.0, 0.08, 0.08, 0.24, 0.04, 0.16, 0.0, 0.0], [0.0, 0.16, 0.32, 0.04, 0.4, 0.0, 0.08, 0.0, 0.0], [0.0, 0.4, 0.2, 0.0, 0.24, 0.0, 0.16, 0.0, 0.0], [0.04, 0.48, 0.32, 0.0, 0.12, 0.0, 0.04, 0.0, 0.0], [0.0, 0.16, 0.44, 0.0, 0.28, 0.0, 0.12, 0.0, 0.0], [0.52, 0.0, 0.0, 0.0, 0.0, 0.48, 0.0, 0.0, 0.0], [0.92, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0], [0.44, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0], [0.0, 0.0, 0.16, 0.28, 0.44, 0.0, 0.12, 0.0, 0.0], [0.8, 0.0, 0.0, 0.04, 0.04, 0.08, 0.04, 0.0, 0.0], [0.36, 0.0, 0.12, 0.04, 0.16, 0.0, 0.24, 0.04, 0.04], [0.88, 0.0, 0.0, 0.0, 0.0, 0.04, 0.04, 0.04, 0.0], [0.04, 0.04, 0.32, 0.0, 0.4, 0.0, 0.2, 0.0, 0.0], [0.12, 0.04, 0.12, 0.0, 0.4, 0.0, 0.32, 0.0, 0.0], [0.92, 0.0, 0.0, 0.0, 0.04, 0.0, 0.04, 0.0, 0.0], [0.2, 0.0, 0.28, 0.0, 0.28, 0.04, 0.2, 0.0, 0.0], [0.6, 0.0, 0.04, 0.0, 0.12, 0.2, 0.04, 0.0, 0.0], [0.12, 0.0, 0.08, 0.2, 0.48, 0.0, 0.08, 0.0, 0.04], [0.16, 0.04, 0.08, 0.16, 0.28, 0.16, 0.08, 0.0, 0.04], [0.0, 0.96, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44, 0.0, 0.24, 0.0, 0.12, 0.04, 0.16, 0.0, 0.0], [0.04, 0.44, 0.32, 0.0, 0.08, 0.0, 0.12, 0.0, 0.0], [0.0, 0.04, 0.24, 0.16, 0.4, 0.0, 0.12, 0.0, 0.04], [0.04, 0.04, 0.48, 0.0, 0.2, 0.0, 0.2, 0.0, 0.04], [0.0, 0.36, 0.28, 0.0, 0.24, 0.0, 0.12, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\n",
    "l1_result.index += 1\n",
    "l1_result.index.name = '#cnum'\n",
    "l1_result.columns = unique_symbols\n",
    "print(l1_result)\n",
    "chip_train = []\n",
    "#pull the percentage for each cnum\n",
    "for x in chip_num:\n",
    "    chip_train.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])\n",
    "#check\n",
    "print(chip_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#199 Error: 0.025111332535743713'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#199 Error: 0.023220110684633255'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#199 Error: 0.024023910984396935'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Number of training iterations\n",
    "num_iters = 200\n",
    "#Size of training dataset\n",
    "num_examples = 2000\n",
    "#Listing out the shapes of each model\n",
    "colors_num = len(chip_train[0])\n",
    "input_size = 3\n",
    "\n",
    "network_shapes = [(input_size, [100], colors_num), (input_size, [100], colors_num), (input_size, [100], colors_num)]\n",
    "#Learning rate of the network\n",
    "rate = 0.001\n",
    "\n",
    "#Generating Training Data\n",
    "input_num = torch.FloatTensor(lab_norm)\n",
    "output_num = torch.FloatTensor(chip_train)\n",
    "#Array of losses over training period for each network\n",
    "for net_num, shape in enumerate(network_shapes):\n",
    "    print('Network Shape:',flush = True)\n",
    "    print('Input Size = ' + str(shape[0]), flush = True)\n",
    "    print('Hidden Size = ' + str(shape[1]), flush = True)\n",
    "    print('Output Size = ' + str(shape[2]), flush = True)\n",
    "    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n",
    "                        hiddenSize = shape[1] , learning_rate = rate)\n",
    "    \n",
    "\n",
    "    for i in range(num_iters):\n",
    "        #Calculating l1 error\n",
    "        error = NN.l1error(output_num, NN(input_num))\n",
    "        if i == 0: \n",
    "            dh = display(\"#\" + str(i) + \" Error: \" + str(error), display_id=True)\n",
    "        else:\n",
    "            dh.update(\"#\" + str(i) + \" Error: \" + str(error))\n",
    "            \n",
    "        NN.train(input_num, output_num)\n",
    "    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n",
    "    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n",
      "The validation error is: 0.08771716803312302\n",
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n",
      "The validation error is: 0.08773063868284225\n",
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n",
      "The validation error is: 0.08801345527172089\n"
     ]
    }
   ],
   "source": [
    "for net_num, shape in enumerate(network_shapes):\n",
    "    print('Network Shape:',flush = True)\n",
    "    print('Input Size = ' + str(shape[0]), flush = True)\n",
    "    print('Hidden Size = ' + str(shape[1]), flush = True)\n",
    "    print('Output Size = ' + str(shape[2]), flush = True)\n",
    "    \n",
    "    #Loading the network we trained in the prev. section\n",
    "    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n",
    "                        hiddenSize = shape[1] , learning_rate = rate)\n",
    "    NN.load_state_dict(torch.load(\"saved_networks/Net \" + str(net_num)))\n",
    "    validation_error = NN.l1error(output_num, torch.round(NN(input_num)))\n",
    "\n",
    "    print(\"The validation error is: \" + str(validation_error), flush = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "277px",
    "left": "1061px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
