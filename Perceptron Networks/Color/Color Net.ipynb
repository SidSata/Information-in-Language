{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "not working\n",
    "from Language_Data_Scraper.py import *\n",
    "\"\"\"\n",
    "sys.path.insert(0, '..')\n",
    "from net_framework import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   #Lnum  #snum  #cnum Term Abbrev\n",
       "0      1      1      1          LB\n",
       "1      1      1      2          LB\n",
       "2      1      1      3          LE\n",
       "3      1      1      4          WK\n",
       "4      1      1      5          LF"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#Lnum</th>\n      <th>#snum</th>\n      <th>#cnum</th>\n      <th>Term Abbrev</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>LB</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>LB</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>LE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>WK</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>LF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\n",
    "term_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\n",
    "term_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   #cnum  Normalized-L  Normalized-a  Normalized-b\n0    141      1.000000     -0.025675     -0.138822\n1    274      0.876301     -0.025504     -0.138822\n2    129      0.876301      0.070445     -0.106039\n3    230      0.876301      0.070101     -0.089951\n4    302      0.876301      0.070617     -0.072041",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#cnum</th>\n      <th>Normalized-L</th>\n      <th>Normalized-a</th>\n      <th>Normalized-b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>141</td>\n      <td>1.000000</td>\n      <td>-0.025675</td>\n      <td>-0.138822</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274</td>\n      <td>0.876301</td>\n      <td>-0.025504</td>\n      <td>-0.138822</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>129</td>\n      <td>0.876301</td>\n      <td>0.070445</td>\n      <td>-0.106039</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>230</td>\n      <td>0.876301</td>\n      <td>0.070101</td>\n      <td>-0.089951</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>302</td>\n      <td>0.876301</td>\n      <td>0.070617</td>\n      <td>-0.072041</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\n",
    "locations = cnum_data[['#cnum']]\n",
    "locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\n",
    "locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
    "locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n",
    "display(locations.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.sort_values('#cnum')\n",
    "chip_num = list(locations['#cnum'])\n",
    "lab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = term_data[term_data.get('#Lnum').eq(1)]\n",
    "unique_symbols = list(l1['Term Abbrev'].unique())\n",
    "l1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\n",
    "l1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         LB    LE    WK    LF     F     G     S   GB    FU\n#cnum                                                     \n1      0.36  0.00  0.00  0.04  0.08  0.52  0.00  0.0  0.00\n2      0.12  0.00  0.04  0.12  0.60  0.04  0.00  0.0  0.08\n3      0.00  0.96  0.04  0.00  0.00  0.00  0.00  0.0  0.00\n4      0.28  0.00  0.40  0.00  0.08  0.04  0.20  0.0  0.00\n5      0.04  0.00  0.00  0.20  0.68  0.08  0.00  0.0  0.00\n...     ...   ...   ...   ...   ...   ...   ...  ...   ...\n326    0.08  0.20  0.36  0.00  0.20  0.00  0.12  0.0  0.04\n327    0.04  0.00  0.00  0.68  0.20  0.04  0.04  0.0  0.00\n328    0.64  0.00  0.08  0.00  0.00  0.20  0.08  0.0  0.00\n329    0.08  0.08  0.40  0.00  0.12  0.00  0.28  0.0  0.04\n330    0.04  0.00  0.00  0.72  0.24  0.00  0.00  0.0  0.00\n\n[330 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\n",
    "l1_result.index += 1\n",
    "l1_result.index.name = '#cnum'\n",
    "l1_result.columns = unique_symbols\n",
    "print(l1_result)\n",
    "chip_norm = []\n",
    "#pull the percentage for each cnum\n",
    "for x in chip_num:\n",
    "    chip_norm.append((l1_result.loc[l1[\"#cnum\"]==x]).values.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of training iterations\n",
    "num_iters = 5000\n",
    "#Size of training dataset\n",
    "num_examples = 2000\n",
    "#Listing out the shapes of each model\n",
    "colors_num = len(chip_norm[0])\n",
    "input_size = 3\n",
    "\n",
    "network_shapes = [(input_size, [100], colors_num), (input_size, [100], colors_num), (input_size, [100], colors_num)]\n",
    "#Learning rate of the network\n",
    "rate = 0.001\n",
    "\n",
    "#Generating Training Data\n",
    "lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.1)\n",
    "\n",
    "input_train = torch.FloatTensor(lab_train)\n",
    "output_train = torch.FloatTensor(chip_train)\n",
    "input_test= torch.FloatTensor(lab_test)\n",
    "output_test = torch.FloatTensor(chip_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'#0 Error: 0.3937310576438904'"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'#0 Error: 0.4112871289253235'"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'#0 Error: 0.3904036581516266'"
     },
     "metadata": {}
    }
   ],
   "source": [
    "#Array of losses over training period for each network\n",
    "for net_num, shape in enumerate(network_shapes):\n",
    "    print('Network Shape:',flush = True)\n",
    "    print('Input Size = ' + str(shape[0]), flush = True)\n",
    "    print('Hidden Size = ' + str(shape[1]), flush = True)\n",
    "    print('Output Size = ' + str(shape[2]), flush = True)\n",
    "    NN = Neural_Network(inputSize = 3, outputSize = colors_num, hiddenSize = [3,3,3] , learning_rate = 0.001)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        #Calculating l1 error\n",
    "        error = NN.l1error(output_train, NN(input_train))\n",
    "        if i == 0: \n",
    "            dh = display(\"#\" + str(i) + \" Error: \" + str(error), display_id=True)\n",
    "        else:\n",
    "            dh.update(\"#\" + str(i) + \" Error: \" + str(error))\n",
    "            \n",
    "        NN.train(input_train, output_train)\n",
    "    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n",
    "    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Network Shape:\n",
      "Input Size = 3\n",
      "Hidden Size = [100]\n",
      "Output Size = 9\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Neural_Network:\n\tUnexpected key(s) in state_dict: \"model.4.weight\", \"model.4.bias\", \"model.6.weight\", \"model.6.bias\". \n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([3, 3]) from checkpoint, the shape in current model is torch.Size([100, 3]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for model.2.weight: copying a param with shape torch.Size([3, 3]) from checkpoint, the shape in current model is torch.Size([9, 100]).\n\tsize mismatch for model.2.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([9]).",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-70ff175db6a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n\u001b[1;32m      9\u001b[0m                         hiddenSize = shape[1] , learning_rate = rate)\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_networks/Net \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Neural_Network:\n\tUnexpected key(s) in state_dict: \"model.4.weight\", \"model.4.bias\", \"model.6.weight\", \"model.6.bias\". \n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([3, 3]) from checkpoint, the shape in current model is torch.Size([100, 3]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for model.2.weight: copying a param with shape torch.Size([3, 3]) from checkpoint, the shape in current model is torch.Size([9, 100]).\n\tsize mismatch for model.2.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([9])."
     ]
    }
   ],
   "source": [
    "for net_num, shape in enumerate(network_shapes):\n",
    "    print('Network Shape:',flush = True)\n",
    "    print('Input Size = ' + str(shape[0]), flush = True)\n",
    "    print('Hidden Size = ' + str(shape[1]), flush = True)\n",
    "    print('Output Size = ' + str(shape[2]), flush = True)\n",
    "    # Loading the network we trained in the prev. section\n",
    "    \n",
    "    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n",
    "                        hiddenSize = shape[1] , learning_rate = rate)\n",
    "    NN.load_state_dict(torch.load(\"saved_networks/Net \" + str(net_num)))\n",
    "    \n",
    "    validation_error = NN.l1error(output_test, NN(input_test))\n",
    "    max_error = np.max(np.abs((output_test - NN(input_test)).detach().numpy()))\n",
    "    print(\"The validation error is: \" + str(validation_error), flush = True)  \n",
    "    print(\"The maximum error is:\" + str(max_error), flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "277px",
    "left": "1061px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}