{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "not working\n",
    "from Language_Data_Scraper.py import *\n",
    "\"\"\"\n",
    "sys.path.insert(0, '..')\n",
    "from net_framework import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   #Lnum  #snum  #cnum Term Abbrev\n",
       "0      1      1      1          LB\n",
       "1      1      1      2          LB\n",
       "2      1      1      3          LE\n",
       "3      1      1      4          WK\n",
       "4      1      1      5          LF"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#Lnum</th>\n      <th>#snum</th>\n      <th>#cnum</th>\n      <th>Term Abbrev</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>LB</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>LB</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>LE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>WK</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>LF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "term_data = pd.read_csv('term.txt', sep=\"\\t\", header=None)\n",
    "term_data.columns = [\"#Lnum\", \"#snum\", \"#cnum\", \"Term Abbrev\"]\n",
    "term_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   #cnum  Normalized-L  Normalized-a  Normalized-b\n0    141      1.000000     -0.025675     -0.138822\n1    274      0.876301     -0.025504     -0.138822\n2    129      0.876301      0.070445     -0.106039\n3    230      0.876301      0.070101     -0.089951\n4    302      0.876301      0.070617     -0.072041",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#cnum</th>\n      <th>Normalized-L</th>\n      <th>Normalized-a</th>\n      <th>Normalized-b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>141</td>\n      <td>1.000000</td>\n      <td>-0.025675</td>\n      <td>-0.138822</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>274</td>\n      <td>0.876301</td>\n      <td>-0.025504</td>\n      <td>-0.138822</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>129</td>\n      <td>0.876301</td>\n      <td>0.070445</td>\n      <td>-0.106039</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>230</td>\n      <td>0.876301</td>\n      <td>0.070101</td>\n      <td>-0.089951</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>302</td>\n      <td>0.876301</td>\n      <td>0.070617</td>\n      <td>-0.072041</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "cnum_data = pd.read_csv('cnum-vhcm-lab-new.txt', sep=\"\\t\")\n",
    "locations = cnum_data[['#cnum']]\n",
    "locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).max()\n",
    "locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
    "locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n",
    "display(locations.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.sort_values('#cnum')\n",
    "chip_num = list(locations['#cnum'])\n",
    "lab_norm = [[row[2], row[3], row[4]] for row in locations.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = term_data[term_data.get('#Lnum').eq(1)]\n",
    "unique_symbols = list(l1['Term Abbrev'].unique())\n",
    "l1_grouped = l1.groupby('#cnum')['Term Abbrev'].apply(list)\n",
    "l1_chip_abbrev_percentage = [[(l1_grouped[i + 1].count(abbrev) / len(l1_grouped[i + 1])) for abbrev in unique_symbols] for i in range(len(l1_grouped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         LB    LE    WK    LF     F     G     S   GB    FU\n#cnum                                                     \n1      0.36  0.00  0.00  0.04  0.08  0.52  0.00  0.0  0.00\n2      0.12  0.00  0.04  0.12  0.60  0.04  0.00  0.0  0.08\n3      0.00  0.96  0.04  0.00  0.00  0.00  0.00  0.0  0.00\n4      0.28  0.00  0.40  0.00  0.08  0.04  0.20  0.0  0.00\n5      0.04  0.00  0.00  0.20  0.68  0.08  0.00  0.0  0.00\n...     ...   ...   ...   ...   ...   ...   ...  ...   ...\n326    0.08  0.20  0.36  0.00  0.20  0.00  0.12  0.0  0.04\n327    0.04  0.00  0.00  0.68  0.20  0.04  0.04  0.0  0.00\n328    0.64  0.00  0.08  0.00  0.00  0.20  0.08  0.0  0.00\n329    0.08  0.08  0.40  0.00  0.12  0.00  0.28  0.0  0.04\n330    0.04  0.00  0.00  0.72  0.24  0.00  0.00  0.0  0.00\n\n[330 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "l1_result = pd.DataFrame(l1_chip_abbrev_percentage)\n",
    "l1_result.index += 1\n",
    "l1_result.index.name = '#cnum'\n",
    "l1_result.columns = unique_symbols\n",
    "print(l1_result)\n",
    "chip_norm = []\n",
    "\n",
    "# pull the percentage for each cnum\n",
    "for x in chip_num:\n",
    "    chip_norm.append(l1_result.loc[x,:].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of training iterations\n",
    "num_iters = 5000\n",
    "#Size of training dataset\n",
    "num_examples = 2000\n",
    "#Listing out the shapes of each model\n",
    "colors_num = len(chip_norm[0])\n",
    "input_size = 3\n",
    "\n",
    "network_shapes = [(input_size, [100], colors_num), (input_size, [100], colors_num), (input_size, [100], colors_num)]\n",
    "#Learning rate of the network\n",
    "rate = 0.001\n",
    "\n",
    "#Generating Training Data\n",
    "lab_train, lab_test, chip_train, chip_test = train_test_split(lab_norm, chip_norm, test_size=0.1)\n",
    "\n",
    "input_train = torch.FloatTensor(lab_train)\n",
    "output_train = torch.FloatTensor(chip_train)\n",
    "input_test= torch.FloatTensor(lab_test)\n",
    "output_test = torch.FloatTensor(chip_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of losses over training period for each network\n",
    "for net_num, shape in enumerate(network_shapes):\n",
    "    print('Network Shape:',flush = True)\n",
    "    print('Input Size = ' + str(shape[0]), flush = True)\n",
    "    print('Hidden Size = ' + str(shape[1]), flush = True)\n",
    "    print('Output Size = ' + str(shape[2]), flush = True)\n",
    "    NN = Neural_Network(inputSize = 3, outputSize = colors_num, hiddenSize = [3,3,3] , learning_rate = 0.001)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        #Calculating l1 error\n",
    "        error = NN.l1error(output_train, NN(input_train))\n",
    "        if i == 0: \n",
    "            dh = display(\"#\" + str(i) + \" Error: \" + str(error), display_id=True)\n",
    "        else:\n",
    "            dh.update(\"#\" + str(i) + \" Error: \" + str(error))\n",
    "            \n",
    "        NN.train(input_train, output_train)\n",
    "    #Saves the training results in a filed named \"Net 0\", \"Net 1\", etc. \n",
    "    NN.saveWeights(model = NN, path = \"saved_networks/Net \" + str(net_num));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net_num, shape in enumerate(network_shapes):\n",
    "    print('Network Shape:',flush = True)\n",
    "    print('Input Size = ' + str(shape[0]), flush = True)\n",
    "    print('Hidden Size = ' + str(shape[1]), flush = True)\n",
    "    print('Output Size = ' + str(shape[2]), flush = True)\n",
    "    # Loading the network we trained in the prev. section\n",
    "    \n",
    "    NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n",
    "                        hiddenSize = shape[1] , learning_rate = rate)\n",
    "    NN.load_state_dict(torch.load(\"saved_networks/Net \" + str(net_num)))\n",
    "    \n",
    "    validation_error = NN.l1error(output_test, NN(input_test))\n",
    "    max_error = np.max(np.abs((output_test - NN(input_test)).detach().numpy()))\n",
    "    print(\"The validation error is: \" + str(validation_error), flush = True)  \n",
    "    print(\"The maximum error is:\" + str(max_error), flush = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "277px",
    "left": "1061px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}